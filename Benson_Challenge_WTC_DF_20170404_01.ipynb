{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "import MP_functions as dfutil\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing & Loading Data\n",
    "\n",
    "Make sure to unzip the pickles.zip into the root folder for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from load_pickles import df as pickle\n",
    "df = dfutil.open_dataframe_pickle('MTA_DATA_SPRING_2014_to_2016_FULL.pickle')\n",
    "dtp = dfutil.open_dataframe_pickle('daily_throughput.pickle')\n",
    "htp = dfutil.open_dataframe_pickle('hourly_throughput.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanData(frame):\n",
    "    # Strip whitespace from column names\n",
    "    frame.columns = [s.strip() for s in frame.columns.values]\n",
    "\n",
    "    # Create datetime column with datetime datatype\n",
    "    frame['Datetime'] = pd.to_datetime(frame.DATE + ' ' + frame.TIME,\n",
    "                                        format = '%m/%d/%Y %H:%M:%S')\n",
    "    frame['Day_of_week'] = frame['Datetime'].apply(lambda row: row.strftime(\"%A\"))\n",
    "    \n",
    "    # Chain methods together to further clean data:\n",
    "        # drop old date and time columns\n",
    "        # rename columns\n",
    "    \n",
    "    dict_col_rename = {'C/A' : 'C_A', 'UNIT' : 'Unit', 'STATION' : 'Station', 'LINENAME' : 'Linename',\n",
    "                      'DIVISION' : 'Division', 'DESC' : 'Desc', 'ENTRIES' : 'Entries', 'EXITS' : 'Exits',\n",
    "                      'DATE' : 'Date'}    \n",
    "\n",
    "    frame2 = frame.rename(columns = dict_col_rename)\n",
    "    \n",
    "    # Check uniqueness of rows/indexes by getting counts.\n",
    "    (frame2\n",
    "     .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Datetime'])\n",
    "     .count() #.Entries.count()\n",
    "     .reset_index()\n",
    "     .sort_values('Entries', ascending = False)\n",
    "    )\n",
    "    \n",
    "    # Drop duplicates.\n",
    "    return frame2.drop_duplicates(subset=['C_A', 'Unit', 'SCP', 'Station', 'Datetime'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcDailyThroughput(frame):\n",
    "    \n",
    "    # group daily entries and daily exits\n",
    "    daily_entries = (frame\n",
    "                      .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Date'])\n",
    "                      .Entries\n",
    "                      .first()\n",
    "                      .reset_index()\n",
    "                    )\n",
    "\n",
    "    daily_exits = (frame\n",
    "                    .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Date'])\n",
    "                    .Exits\n",
    "                    .first()\n",
    "                    .reset_index()\n",
    "                   )\n",
    "    \n",
    "    # Calculate the differences by day\n",
    "    daily_entries[[\"Prev_date\", \"Prev_entries\"]] = (daily_entries\n",
    "                                                     .groupby([\"C_A\", \"Unit\", \"SCP\", \"Station\"])[\"Date\", \"Entries\"]\n",
    "                                                     .transform(lambda grp: grp.shift(1)))\n",
    "\n",
    "    daily_exits[[\"Prev_date\", \"Prev_exits\"]]   = (daily_exits\n",
    "                                                   .groupby([\"C_A\", \"Unit\", \"SCP\", \"Station\"])[\"Date\", \"Exits\"]\n",
    "                                                   .transform(lambda grp: grp.shift(1)))\n",
    "\n",
    "    # Drop all the null values generated above\n",
    "    daily_entries.dropna(subset=[\"Prev_date\"], axis=0, inplace=True)\n",
    "    daily_exits.dropna(subset=[\"Prev_date\"], axis=0, inplace=True)\n",
    "\n",
    "\n",
    "    daily_entries[\"Daily_Entries\"] = daily_entries.apply(get_daily_counts, axis=1, args=(1000000, ['Entries', 'Prev_entries']))\n",
    "    daily_exits[\"Daily_Exits\"] = daily_exits.apply(get_daily_counts, axis=1, args=(1000000, ['Exits', 'Prev_exits']))\n",
    "    \n",
    "    daily = pd.merge(daily_entries, daily_exits, on=['C_A','Unit','SCP', 'Station', 'Date', 'Prev_date'])\n",
    "    daily['Total_throughput'] = daily['Daily_Entries'] + daily['Daily_Exits']\n",
    "    \n",
    "    return (daily\n",
    "             .groupby(['Station', 'Date'])\n",
    "             .sum()\n",
    "            #  .sort_values(by=['Total_throughput'], ascending=False)\n",
    "             .loc[:,['Daily_Entries', 'Daily_Exits', 'Total_throughput']]\n",
    "            #  .frame()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcDailyThroughput(frame):\n",
    "    \n",
    "    # group daily entries and daily exits\n",
    "    daily_entries = (frame\n",
    "                      .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Date'])\n",
    "                      .Entries\n",
    "                      .first()\n",
    "                      .reset_index()\n",
    "                    )\n",
    "\n",
    "    daily_exits = (frame\n",
    "                    .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Date'])\n",
    "                    .Exits\n",
    "                    .first()\n",
    "                    .reset_index()\n",
    "                   )\n",
    "    \n",
    "    # Calculate the differences by day\n",
    "    daily_entries[[\"Prev_date\", \"Prev_entries\"]] = (daily_entries\n",
    "                                                     .groupby([\"C_A\", \"Unit\", \"SCP\", \"Station\"])[\"Date\", \"Entries\"]\n",
    "                                                     .transform(lambda grp: grp.shift(1)))\n",
    "\n",
    "    daily_exits[[\"Prev_date\", \"Prev_exits\"]]   = (daily_exits\n",
    "                                                   .groupby([\"C_A\", \"Unit\", \"SCP\", \"Station\"])[\"Date\", \"Exits\"]\n",
    "                                                   .transform(lambda grp: grp.shift(1)))\n",
    "\n",
    "    # Drop all the null values generated above\n",
    "    daily_entries.dropna(subset=[\"Prev_date\"], axis=0, inplace=True)\n",
    "    daily_exits.dropna(subset=[\"Prev_date\"], axis=0, inplace=True)\n",
    "\n",
    "\n",
    "    daily_entries[\"Daily_Entries\"] = daily_entries.apply(get_daily_counts, axis=1, args=(1000000, ['Entries', 'Prev_entries']))\n",
    "    daily_exits[\"Daily_Exits\"] = daily_exits.apply(get_daily_counts, axis=1, args=(1000000, ['Exits', 'Prev_exits']))\n",
    "    \n",
    "    daily = pd.merge(daily_entries, daily_exits, on=['C_A','Unit','SCP', 'Station', 'Date', 'Prev_date'])\n",
    "    daily['Total_throughput'] = daily['Daily_Entries'] + daily['Daily_Exits']\n",
    "    \n",
    "    return (daily\n",
    "             .groupby(['Station', 'Date'])\n",
    "             .sum()\n",
    "            #  .sort_values(by=['Total_throughput'], ascending=False)\n",
    "             .loc[:,['Daily_Entries', 'Daily_Exits', 'Total_throughput']]\n",
    "            #  .frame()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcDailyEntries(frame):\n",
    "    \n",
    "    # group daily entries and daily exits\n",
    "    daily_entries = (frame\n",
    "                      .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Date'])\n",
    "                      .Entries\n",
    "                      .first()\n",
    "                      .reset_index()\n",
    "                    )\n",
    "    \n",
    "    # Calculate the differences by day\n",
    "    daily_entries[[\"Prev_date\", \"Prev_entries\"]] = (daily_entries\n",
    "                                                     .groupby([\"C_A\", \"Unit\", \"SCP\", \"Station\"])[\"Date\", \"Entries\"]\n",
    "                                                     .transform(lambda grp: grp.shift(1)))\n",
    "\n",
    "    # Drop all the null values generated above\n",
    "    daily_entries.dropna(subset=[\"Prev_date\"], axis=0, inplace=True)\n",
    "\n",
    "    daily_entries[\"Daily_Entries\"] = daily_entries.apply(get_daily_counts, axis=1, args=(1000000, ['Entries', 'Prev_entries']))\n",
    "    \n",
    "#     daily = pd.merge(daily_entries, on=['C_A','Unit','SCP', 'Station', 'Date', 'Prev_date'])\n",
    "#     daily['Total_throughput'] = daily['Daily_Entries'] + daily['Daily_Exits']\n",
    "    \n",
    "    return (daily_entries\n",
    "#              .groupby(['Station', 'Date'])\n",
    "#              .mean()\n",
    "            #  .sort_values(by=['Total_throughput'], ascending=False)\n",
    "#              .loc[:,['Daily_Entries']]\n",
    "            #  .frame()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_daily_counts(row, max_diff, cols):\n",
    "    \"\"\"\n",
    "    cols - a list of columns to compute the difference from with format [x, y] = x-y\n",
    "    \"\"\"\n",
    "    #col0 = current\n",
    "    # col11 = prev\n",
    "    CURRENT = cols[0]\n",
    "    PREV = cols[1]\n",
    "    \n",
    "    diff = row[CURRENT] - row[PREV]\n",
    "    if diff < 0:\n",
    "        # May be counter is reversed?\n",
    "        diff = -diff\n",
    "    if diff > max_diff:\n",
    "#         print(row[CURRENT], row[PREV])\n",
    "        diff = min(row[CURRENT], row[PREV])\n",
    "    if diff > max_diff:\n",
    "        # Check it again to make sure we are not giving a counter that's too big\n",
    "        return 0\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcHourThroughput(frame):\n",
    "    shift = frame.copy()\n",
    "\n",
    "    shift[['Datetime_Prev', 'Entries_Prev', 'Exits_Prev']] = (shift\n",
    "                .groupby(['C_A', 'Unit', 'SCP', 'Station'])['Datetime', 'Entries', 'Exits']\n",
    "                .transform(lambda grp: grp.shift(1)))\n",
    "    \n",
    "    shift['Entries'] = shift['Entries'] - shift['Entries_Prev']\n",
    "    shift['Exits'] = shift['Exits'] - shift['Exits_Prev']\n",
    "    shift = shift.dropna(how = 'any')\n",
    "    \n",
    "    shift['Throughput'] = shift['Entries'] + shift['Exits']\n",
    "    \n",
    "    return shift.loc[:,['Station','Datetime','Throughput']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make note to save and open pickles here:\n",
    "# dfutil.save_dataframe_as_pickle(df,'MTA_DATA_SPRING_2014_to_2016_FULL.pickle')\n",
    "# df_pickle = dfutil.open_dataframe_pickle('MTA_DATA_SPRING_2014_to_2016_FULL.pickle') # returns a df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = df['Date'].str.contains('/2016')\n",
    "df_2016 = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daily_2016 = calcDailyEntries(df_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   540040.00\n",
       "mean      1199.13\n",
       "std       5319.69\n",
       "min          0.00\n",
       "25%        282.00\n",
       "50%        867.00\n",
       "75%       1698.00\n",
       "max     979909.00\n",
       "Name: Daily_Entries, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_2016['Daily_Entries'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o200k_mask = daily_2016['Daily_Entries'] < 700000\n",
    "less250k = daily_2016[o200k_mask].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_A</th>\n",
       "      <th>Unit</th>\n",
       "      <th>SCP</th>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th>Entries</th>\n",
       "      <th>Prev_date</th>\n",
       "      <th>Prev_entries</th>\n",
       "      <th>Daily_Entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>02/28/2016</td>\n",
       "      <td>5563262</td>\n",
       "      <td>02/27/2016</td>\n",
       "      <td>5562172.00</td>\n",
       "      <td>1090.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>02/29/2016</td>\n",
       "      <td>5564033</td>\n",
       "      <td>02/28/2016</td>\n",
       "      <td>5563262.00</td>\n",
       "      <td>771.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/01/2016</td>\n",
       "      <td>5565799</td>\n",
       "      <td>02/29/2016</td>\n",
       "      <td>5564033.00</td>\n",
       "      <td>1766.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/02/2016</td>\n",
       "      <td>5567572</td>\n",
       "      <td>03/01/2016</td>\n",
       "      <td>5565799.00</td>\n",
       "      <td>1773.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/03/2016</td>\n",
       "      <td>5569303</td>\n",
       "      <td>03/02/2016</td>\n",
       "      <td>5567572.00</td>\n",
       "      <td>1731.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/04/2016</td>\n",
       "      <td>5571113</td>\n",
       "      <td>03/03/2016</td>\n",
       "      <td>5569303.00</td>\n",
       "      <td>1810.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/05/2016</td>\n",
       "      <td>5572932</td>\n",
       "      <td>03/04/2016</td>\n",
       "      <td>5571113.00</td>\n",
       "      <td>1819.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/06/2016</td>\n",
       "      <td>5574011</td>\n",
       "      <td>03/05/2016</td>\n",
       "      <td>5572932.00</td>\n",
       "      <td>1079.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/07/2016</td>\n",
       "      <td>5574814</td>\n",
       "      <td>03/06/2016</td>\n",
       "      <td>5574011.00</td>\n",
       "      <td>803.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/08/2016</td>\n",
       "      <td>5576527</td>\n",
       "      <td>03/07/2016</td>\n",
       "      <td>5574814.00</td>\n",
       "      <td>1713.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/09/2016</td>\n",
       "      <td>5578316</td>\n",
       "      <td>03/08/2016</td>\n",
       "      <td>5576527.00</td>\n",
       "      <td>1789.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/10/2016</td>\n",
       "      <td>5580045</td>\n",
       "      <td>03/09/2016</td>\n",
       "      <td>5578316.00</td>\n",
       "      <td>1729.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/11/2016</td>\n",
       "      <td>5581828</td>\n",
       "      <td>03/10/2016</td>\n",
       "      <td>5580045.00</td>\n",
       "      <td>1783.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/12/2016</td>\n",
       "      <td>5583673</td>\n",
       "      <td>03/11/2016</td>\n",
       "      <td>5581828.00</td>\n",
       "      <td>1845.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/13/2016</td>\n",
       "      <td>5584835</td>\n",
       "      <td>03/12/2016</td>\n",
       "      <td>5583673.00</td>\n",
       "      <td>1162.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/14/2016</td>\n",
       "      <td>5585473</td>\n",
       "      <td>03/13/2016</td>\n",
       "      <td>5584835.00</td>\n",
       "      <td>638.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/15/2016</td>\n",
       "      <td>5586640</td>\n",
       "      <td>03/14/2016</td>\n",
       "      <td>5585473.00</td>\n",
       "      <td>1167.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/16/2016</td>\n",
       "      <td>5587644</td>\n",
       "      <td>03/15/2016</td>\n",
       "      <td>5586640.00</td>\n",
       "      <td>1004.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/17/2016</td>\n",
       "      <td>5588611</td>\n",
       "      <td>03/16/2016</td>\n",
       "      <td>5587644.00</td>\n",
       "      <td>967.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/18/2016</td>\n",
       "      <td>5589621</td>\n",
       "      <td>03/17/2016</td>\n",
       "      <td>5588611.00</td>\n",
       "      <td>1010.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/19/2016</td>\n",
       "      <td>5590801</td>\n",
       "      <td>03/18/2016</td>\n",
       "      <td>5589621.00</td>\n",
       "      <td>1180.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/20/2016</td>\n",
       "      <td>5591699</td>\n",
       "      <td>03/19/2016</td>\n",
       "      <td>5590801.00</td>\n",
       "      <td>898.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/21/2016</td>\n",
       "      <td>5592345</td>\n",
       "      <td>03/20/2016</td>\n",
       "      <td>5591699.00</td>\n",
       "      <td>646.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/22/2016</td>\n",
       "      <td>5593648</td>\n",
       "      <td>03/21/2016</td>\n",
       "      <td>5592345.00</td>\n",
       "      <td>1303.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/23/2016</td>\n",
       "      <td>5594566</td>\n",
       "      <td>03/22/2016</td>\n",
       "      <td>5593648.00</td>\n",
       "      <td>918.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/24/2016</td>\n",
       "      <td>5595296</td>\n",
       "      <td>03/23/2016</td>\n",
       "      <td>5594566.00</td>\n",
       "      <td>730.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/25/2016</td>\n",
       "      <td>5595296</td>\n",
       "      <td>03/24/2016</td>\n",
       "      <td>5595296.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/26/2016</td>\n",
       "      <td>5595746</td>\n",
       "      <td>03/25/2016</td>\n",
       "      <td>5595296.00</td>\n",
       "      <td>450.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/27/2016</td>\n",
       "      <td>5595746</td>\n",
       "      <td>03/26/2016</td>\n",
       "      <td>5595746.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>03/28/2016</td>\n",
       "      <td>5595746</td>\n",
       "      <td>03/27/2016</td>\n",
       "      <td>5595746.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544639</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>05/26/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>05/25/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544640</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>05/27/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>05/26/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544641</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>05/28/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>05/27/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544642</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>05/29/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>05/28/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544643</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>05/30/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>05/29/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544644</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>05/31/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>05/30/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544645</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/01/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>05/31/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544646</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/02/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/01/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544647</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/03/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/02/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544648</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/04/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/03/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544649</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/05/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/04/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544650</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/06/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/05/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544651</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/07/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/06/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544652</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/08/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/07/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544653</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/09/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/08/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544654</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/10/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/09/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544655</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/11/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/10/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544656</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/12/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/11/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544657</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/13/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/12/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544658</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/14/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/13/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544659</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/15/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/14/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544660</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/16/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/15/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544661</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/17/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/16/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544662</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/18/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/17/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544663</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/19/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/18/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544664</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/20/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/19/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544665</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/21/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/20/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544666</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/22/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/21/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544667</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/23/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/22/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544668</th>\n",
       "      <td>TRAM2</td>\n",
       "      <td>R469</td>\n",
       "      <td>00-05-01</td>\n",
       "      <td>RIT-ROOSEVELT</td>\n",
       "      <td>06/24/2016</td>\n",
       "      <td>5554</td>\n",
       "      <td>06/23/2016</td>\n",
       "      <td>5554.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>539993 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          C_A  Unit       SCP        Station        Date  Entries   Prev_date  \\\n",
       "1        A002  R051  02-00-00          59 ST  02/28/2016  5563262  02/27/2016   \n",
       "2        A002  R051  02-00-00          59 ST  02/29/2016  5564033  02/28/2016   \n",
       "3        A002  R051  02-00-00          59 ST  03/01/2016  5565799  02/29/2016   \n",
       "4        A002  R051  02-00-00          59 ST  03/02/2016  5567572  03/01/2016   \n",
       "5        A002  R051  02-00-00          59 ST  03/03/2016  5569303  03/02/2016   \n",
       "6        A002  R051  02-00-00          59 ST  03/04/2016  5571113  03/03/2016   \n",
       "7        A002  R051  02-00-00          59 ST  03/05/2016  5572932  03/04/2016   \n",
       "8        A002  R051  02-00-00          59 ST  03/06/2016  5574011  03/05/2016   \n",
       "9        A002  R051  02-00-00          59 ST  03/07/2016  5574814  03/06/2016   \n",
       "10       A002  R051  02-00-00          59 ST  03/08/2016  5576527  03/07/2016   \n",
       "11       A002  R051  02-00-00          59 ST  03/09/2016  5578316  03/08/2016   \n",
       "12       A002  R051  02-00-00          59 ST  03/10/2016  5580045  03/09/2016   \n",
       "13       A002  R051  02-00-00          59 ST  03/11/2016  5581828  03/10/2016   \n",
       "14       A002  R051  02-00-00          59 ST  03/12/2016  5583673  03/11/2016   \n",
       "15       A002  R051  02-00-00          59 ST  03/13/2016  5584835  03/12/2016   \n",
       "16       A002  R051  02-00-00          59 ST  03/14/2016  5585473  03/13/2016   \n",
       "17       A002  R051  02-00-00          59 ST  03/15/2016  5586640  03/14/2016   \n",
       "18       A002  R051  02-00-00          59 ST  03/16/2016  5587644  03/15/2016   \n",
       "19       A002  R051  02-00-00          59 ST  03/17/2016  5588611  03/16/2016   \n",
       "20       A002  R051  02-00-00          59 ST  03/18/2016  5589621  03/17/2016   \n",
       "21       A002  R051  02-00-00          59 ST  03/19/2016  5590801  03/18/2016   \n",
       "22       A002  R051  02-00-00          59 ST  03/20/2016  5591699  03/19/2016   \n",
       "23       A002  R051  02-00-00          59 ST  03/21/2016  5592345  03/20/2016   \n",
       "24       A002  R051  02-00-00          59 ST  03/22/2016  5593648  03/21/2016   \n",
       "25       A002  R051  02-00-00          59 ST  03/23/2016  5594566  03/22/2016   \n",
       "26       A002  R051  02-00-00          59 ST  03/24/2016  5595296  03/23/2016   \n",
       "27       A002  R051  02-00-00          59 ST  03/25/2016  5595296  03/24/2016   \n",
       "28       A002  R051  02-00-00          59 ST  03/26/2016  5595746  03/25/2016   \n",
       "29       A002  R051  02-00-00          59 ST  03/27/2016  5595746  03/26/2016   \n",
       "30       A002  R051  02-00-00          59 ST  03/28/2016  5595746  03/27/2016   \n",
       "...       ...   ...       ...            ...         ...      ...         ...   \n",
       "544639  TRAM2  R469  00-05-01  RIT-ROOSEVELT  05/26/2016     5554  05/25/2016   \n",
       "544640  TRAM2  R469  00-05-01  RIT-ROOSEVELT  05/27/2016     5554  05/26/2016   \n",
       "544641  TRAM2  R469  00-05-01  RIT-ROOSEVELT  05/28/2016     5554  05/27/2016   \n",
       "544642  TRAM2  R469  00-05-01  RIT-ROOSEVELT  05/29/2016     5554  05/28/2016   \n",
       "544643  TRAM2  R469  00-05-01  RIT-ROOSEVELT  05/30/2016     5554  05/29/2016   \n",
       "544644  TRAM2  R469  00-05-01  RIT-ROOSEVELT  05/31/2016     5554  05/30/2016   \n",
       "544645  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/01/2016     5554  05/31/2016   \n",
       "544646  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/02/2016     5554  06/01/2016   \n",
       "544647  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/03/2016     5554  06/02/2016   \n",
       "544648  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/04/2016     5554  06/03/2016   \n",
       "544649  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/05/2016     5554  06/04/2016   \n",
       "544650  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/06/2016     5554  06/05/2016   \n",
       "544651  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/07/2016     5554  06/06/2016   \n",
       "544652  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/08/2016     5554  06/07/2016   \n",
       "544653  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/09/2016     5554  06/08/2016   \n",
       "544654  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/10/2016     5554  06/09/2016   \n",
       "544655  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/11/2016     5554  06/10/2016   \n",
       "544656  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/12/2016     5554  06/11/2016   \n",
       "544657  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/13/2016     5554  06/12/2016   \n",
       "544658  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/14/2016     5554  06/13/2016   \n",
       "544659  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/15/2016     5554  06/14/2016   \n",
       "544660  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/16/2016     5554  06/15/2016   \n",
       "544661  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/17/2016     5554  06/16/2016   \n",
       "544662  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/18/2016     5554  06/17/2016   \n",
       "544663  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/19/2016     5554  06/18/2016   \n",
       "544664  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/20/2016     5554  06/19/2016   \n",
       "544665  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/21/2016     5554  06/20/2016   \n",
       "544666  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/22/2016     5554  06/21/2016   \n",
       "544667  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/23/2016     5554  06/22/2016   \n",
       "544668  TRAM2  R469  00-05-01  RIT-ROOSEVELT  06/24/2016     5554  06/23/2016   \n",
       "\n",
       "        Prev_entries  Daily_Entries  \n",
       "1         5562172.00        1090.00  \n",
       "2         5563262.00         771.00  \n",
       "3         5564033.00        1766.00  \n",
       "4         5565799.00        1773.00  \n",
       "5         5567572.00        1731.00  \n",
       "6         5569303.00        1810.00  \n",
       "7         5571113.00        1819.00  \n",
       "8         5572932.00        1079.00  \n",
       "9         5574011.00         803.00  \n",
       "10        5574814.00        1713.00  \n",
       "11        5576527.00        1789.00  \n",
       "12        5578316.00        1729.00  \n",
       "13        5580045.00        1783.00  \n",
       "14        5581828.00        1845.00  \n",
       "15        5583673.00        1162.00  \n",
       "16        5584835.00         638.00  \n",
       "17        5585473.00        1167.00  \n",
       "18        5586640.00        1004.00  \n",
       "19        5587644.00         967.00  \n",
       "20        5588611.00        1010.00  \n",
       "21        5589621.00        1180.00  \n",
       "22        5590801.00         898.00  \n",
       "23        5591699.00         646.00  \n",
       "24        5592345.00        1303.00  \n",
       "25        5593648.00         918.00  \n",
       "26        5594566.00         730.00  \n",
       "27        5595296.00           0.00  \n",
       "28        5595296.00         450.00  \n",
       "29        5595746.00           0.00  \n",
       "30        5595746.00           0.00  \n",
       "...              ...            ...  \n",
       "544639       5554.00           0.00  \n",
       "544640       5554.00           0.00  \n",
       "544641       5554.00           0.00  \n",
       "544642       5554.00           0.00  \n",
       "544643       5554.00           0.00  \n",
       "544644       5554.00           0.00  \n",
       "544645       5554.00           0.00  \n",
       "544646       5554.00           0.00  \n",
       "544647       5554.00           0.00  \n",
       "544648       5554.00           0.00  \n",
       "544649       5554.00           0.00  \n",
       "544650       5554.00           0.00  \n",
       "544651       5554.00           0.00  \n",
       "544652       5554.00           0.00  \n",
       "544653       5554.00           0.00  \n",
       "544654       5554.00           0.00  \n",
       "544655       5554.00           0.00  \n",
       "544656       5554.00           0.00  \n",
       "544657       5554.00           0.00  \n",
       "544658       5554.00           0.00  \n",
       "544659       5554.00           0.00  \n",
       "544660       5554.00           0.00  \n",
       "544661       5554.00           0.00  \n",
       "544662       5554.00           0.00  \n",
       "544663       5554.00           0.00  \n",
       "544664       5554.00           0.00  \n",
       "544665       5554.00           0.00  \n",
       "544666       5554.00           0.00  \n",
       "544667       5554.00           0.00  \n",
       "544668       5554.00           0.00  \n",
       "\n",
       "[539993 rows x 9 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less250k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAD3CAYAAAAt8DIpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUqcMHklSpwweSVKnDB5JUqcMHklSp/4/hZHdhI9d2HoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x132678a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "daily_2016['Daily_Entries'].plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YORK ST</td>\n",
       "      <td>METROPOLITAN AVE</td>\n",
       "      <td>JOURNAL SQUARE</td>\n",
       "      <td>BEDFOROAD AVE</td>\n",
       "      <td>GATES AVE</td>\n",
       "      <td>PATH WTC 2</td>\n",
       "      <td>MORISN AVE/SNDVW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUTTER AVE-RUTLD</td>\n",
       "      <td>YORK ST</td>\n",
       "      <td>170 ST</td>\n",
       "      <td>THIRTY ST</td>\n",
       "      <td>GUN HILL ROAD</td>\n",
       "      <td>NASSAU ST</td>\n",
       "      <td>3 AVE 138 ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MYRTLE AVE</td>\n",
       "      <td>BEDFOROAD AVE</td>\n",
       "      <td>PAVEONIA/NEWPORT</td>\n",
       "      <td>YORK ST</td>\n",
       "      <td>YORK ST</td>\n",
       "      <td>UTICA AVE</td>\n",
       "      <td>181 ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14 ST-UNION SQ</td>\n",
       "      <td>MYRTLE AVE</td>\n",
       "      <td>SUTTER AVE-RUTLD</td>\n",
       "      <td>14 ST-UNION SQ</td>\n",
       "      <td>SUTTER AVE-RUTLD</td>\n",
       "      <td>PAVEONIA/NEWPORT</td>\n",
       "      <td>GROVE STREET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116 ST-COLUMBIA</td>\n",
       "      <td>MONTROSE AVE</td>\n",
       "      <td>PATH WTC</td>\n",
       "      <td>MYRTLE AVE</td>\n",
       "      <td>MYRTLE AVE</td>\n",
       "      <td>YORK ST</td>\n",
       "      <td>85 ST-FOREST PARK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Friday            Monday          Saturday          Sunday  \\\n",
       "0           YORK ST  METROPOLITAN AVE    JOURNAL SQUARE   BEDFOROAD AVE   \n",
       "1  SUTTER AVE-RUTLD           YORK ST            170 ST       THIRTY ST   \n",
       "2        MYRTLE AVE     BEDFOROAD AVE  PAVEONIA/NEWPORT         YORK ST   \n",
       "3    14 ST-UNION SQ        MYRTLE AVE  SUTTER AVE-RUTLD  14 ST-UNION SQ   \n",
       "4   116 ST-COLUMBIA      MONTROSE AVE          PATH WTC      MYRTLE AVE   \n",
       "\n",
       "           Thursday           Tuesday          Wednesday  \n",
       "0         GATES AVE        PATH WTC 2   MORISN AVE/SNDVW  \n",
       "1     GUN HILL ROAD         NASSAU ST       3 AVE 138 ST  \n",
       "2           YORK ST         UTICA AVE             181 ST  \n",
       "3  SUTTER AVE-RUTLD  PAVEONIA/NEWPORT       GROVE STREET  \n",
       "4        MYRTLE AVE           YORK ST  85 ST-FOREST PARK  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# less250k = dtp.reset_index()\n",
    "less250k['Day_of_week'] = pd.to_datetime(less250k['Date'], format = '%m/%d/%Y').apply(lambda row: row.strftime(\"%A\"))\n",
    "less250k_mean = less250k.groupby(['Day_of_week','Station'])['Daily_Entries'].mean().reset_index()\n",
    "pivot = less250k_mean.pivot(index='Station', columns='Day_of_week', values = 'Daily_Entries')\n",
    "# dtp[['Daily_Entries', 'Station']].sort_values('Daily_Entries',ascending=False)\n",
    "\n",
    "\n",
    "monday = pivot['Monday'].sort_values(ascending=False).index.values\n",
    "tuesday = pivot['Tuesday'].sort_values(ascending=False).index.values\n",
    "wednesday = pivot['Wednesday'].sort_values(ascending=False).index.values\n",
    "thursday = pivot['Thursday'].sort_values(ascending=False).index.values\n",
    "friday = pivot['Friday'].sort_values(ascending=False).index.values\n",
    "saturday = pivot['Saturday'].sort_values(ascending=False).index.values\n",
    "sunday = pivot['Sunday'].sort_values(ascending=False).index.values\n",
    "\n",
    "dtp_weekly = pd.DataFrame({'Monday': monday,\n",
    "                           'Tuesday': tuesday,\n",
    "                           'Wednesday': wednesday,\n",
    "                           'Thursday': thursday,\n",
    "                           'Friday': friday,\n",
    "                           'Saturday': saturday,\n",
    "                           'Sunday': sunday})\n",
    "\n",
    "dtp_weekly.head(5)\n",
    "\n",
    "# use this if you need to make a pickle\n",
    "# dfutil.save_dataframe_as_pickle(dtp_weekly,'dtp_weekly.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the mean of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Daily_Entries</th>\n",
       "      <th>Daily_Exits</th>\n",
       "      <th>Total_throughput</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1 AVE</th>\n",
       "      <th>02/28/2015</th>\n",
       "      <td>2149122.00</td>\n",
       "      <td>341314.00</td>\n",
       "      <td>2490436.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/28/2016</th>\n",
       "      <td>2153712.00</td>\n",
       "      <td>342328.00</td>\n",
       "      <td>2496040.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/29/2016</th>\n",
       "      <td>14018.00</td>\n",
       "      <td>15107.00</td>\n",
       "      <td>29125.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/01/2015</th>\n",
       "      <td>2151936.00</td>\n",
       "      <td>342214.00</td>\n",
       "      <td>2494150.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/01/2016</th>\n",
       "      <td>2156668.00</td>\n",
       "      <td>343143.00</td>\n",
       "      <td>2499811.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Daily_Entries  Daily_Exits  Total_throughput\n",
       "Station Date                                                    \n",
       "1 AVE   02/28/2015     2149122.00    341314.00        2490436.00\n",
       "        02/28/2016     2153712.00    342328.00        2496040.00\n",
       "        02/29/2016       14018.00     15107.00          29125.00\n",
       "        03/01/2015     2151936.00    342214.00        2494150.00\n",
       "        03/01/2016     2156668.00    343143.00        2499811.00"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34 ST-PENN STA</td>\n",
       "      <td>34 ST-PENN STA</td>\n",
       "      <td>34 ST-PENN STA</td>\n",
       "      <td>34 ST-PENN STA</td>\n",
       "      <td>34 ST-PENN STA</td>\n",
       "      <td>34 ST-PENN STA</td>\n",
       "      <td>34 ST-PENN STA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FULTON ST</td>\n",
       "      <td>FULTON ST</td>\n",
       "      <td>FULTON ST</td>\n",
       "      <td>FULTON ST</td>\n",
       "      <td>FULTON ST</td>\n",
       "      <td>FULTON ST</td>\n",
       "      <td>FULTON ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHAMBERS ST</td>\n",
       "      <td>CHAMBERS ST</td>\n",
       "      <td>CHAMBERS ST</td>\n",
       "      <td>CHAMBERS ST</td>\n",
       "      <td>CHAMBERS ST</td>\n",
       "      <td>CHAMBERS ST</td>\n",
       "      <td>CHAMBERS ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86 ST</td>\n",
       "      <td>86 ST</td>\n",
       "      <td>86 ST</td>\n",
       "      <td>86 ST</td>\n",
       "      <td>86 ST</td>\n",
       "      <td>86 ST</td>\n",
       "      <td>86 ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125 ST</td>\n",
       "      <td>125 ST</td>\n",
       "      <td>125 ST</td>\n",
       "      <td>125 ST</td>\n",
       "      <td>CANAL ST</td>\n",
       "      <td>125 ST</td>\n",
       "      <td>125 ST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Friday          Monday        Saturday          Sunday  \\\n",
       "0  34 ST-PENN STA  34 ST-PENN STA  34 ST-PENN STA  34 ST-PENN STA   \n",
       "1       FULTON ST       FULTON ST       FULTON ST       FULTON ST   \n",
       "2     CHAMBERS ST     CHAMBERS ST     CHAMBERS ST     CHAMBERS ST   \n",
       "3           86 ST           86 ST           86 ST           86 ST   \n",
       "4          125 ST          125 ST          125 ST          125 ST   \n",
       "\n",
       "         Thursday         Tuesday       Wednesday  \n",
       "0  34 ST-PENN STA  34 ST-PENN STA  34 ST-PENN STA  \n",
       "1       FULTON ST       FULTON ST       FULTON ST  \n",
       "2     CHAMBERS ST     CHAMBERS ST     CHAMBERS ST  \n",
       "3           86 ST           86 ST           86 ST  \n",
       "4        CANAL ST          125 ST          125 ST  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtp = dtp.reset_index()\n",
    "dtp['Day_of_week'] = pd.to_datetime(dtp['Date'], format = '%m/%d/%Y').apply(lambda row: row.strftime(\"%A\"))\n",
    "dtp_mean = dtp.groupby(['Day_of_week','Station'])['Daily_Entries'].mean().reset_index()\n",
    "pivot = dtp_mean.pivot(index='Station', columns='Day_of_week', values = 'Daily_Entries')\n",
    "# dtp[['Daily_Entries', 'Station']].sort_values('Daily_Entries',ascending=False)\n",
    "\n",
    "\n",
    "monday = pivot['Monday'].sort_values(ascending=False).index.values\n",
    "tuesday = pivot['Tuesday'].sort_values(ascending=False).index.values\n",
    "wednesday = pivot['Wednesday'].sort_values(ascending=False).index.values\n",
    "thursday = pivot['Thursday'].sort_values(ascending=False).index.values\n",
    "friday = pivot['Friday'].sort_values(ascending=False).index.values\n",
    "saturday = pivot['Saturday'].sort_values(ascending=False).index.values\n",
    "sunday = pivot['Sunday'].sort_values(ascending=False).index.values\n",
    "\n",
    "dtp_weekly = pd.DataFrame({'Monday': monday,\n",
    "                           'Tuesday': tuesday,\n",
    "                           'Wednesday': wednesday,\n",
    "                           'Thursday': thursday,\n",
    "                           'Friday': friday,\n",
    "                           'Saturday': saturday,\n",
    "                           'Sunday': sunday})\n",
    "\n",
    "dtp_weekly.head(5)\n",
    "\n",
    "# use this if you need to make a pickle\n",
    "# dfutil.save_dataframe_as_pickle(dtp_weekly,'dtp_weekly.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Day_of_week</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>482.00</td>\n",
       "      <td>482.00</td>\n",
       "      <td>482.00</td>\n",
       "      <td>482.00</td>\n",
       "      <td>482.00</td>\n",
       "      <td>482.00</td>\n",
       "      <td>482.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1977711.91</td>\n",
       "      <td>1974320.14</td>\n",
       "      <td>2037390.65</td>\n",
       "      <td>2031683.84</td>\n",
       "      <td>2035321.89</td>\n",
       "      <td>2038255.29</td>\n",
       "      <td>2038710.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3394740.05</td>\n",
       "      <td>3401518.74</td>\n",
       "      <td>3504504.94</td>\n",
       "      <td>3503057.65</td>\n",
       "      <td>3495302.91</td>\n",
       "      <td>3502216.72</td>\n",
       "      <td>3502971.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>736.35</td>\n",
       "      <td>366.18</td>\n",
       "      <td>714.38</td>\n",
       "      <td>478.82</td>\n",
       "      <td>774.35</td>\n",
       "      <td>714.88</td>\n",
       "      <td>721.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14325.40</td>\n",
       "      <td>6019.41</td>\n",
       "      <td>14262.58</td>\n",
       "      <td>7912.57</td>\n",
       "      <td>14818.00</td>\n",
       "      <td>13676.63</td>\n",
       "      <td>14831.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>878459.39</td>\n",
       "      <td>879843.93</td>\n",
       "      <td>892638.23</td>\n",
       "      <td>891524.78</td>\n",
       "      <td>909133.43</td>\n",
       "      <td>906872.93</td>\n",
       "      <td>908389.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2434867.57</td>\n",
       "      <td>2429649.42</td>\n",
       "      <td>2506775.21</td>\n",
       "      <td>2493596.83</td>\n",
       "      <td>2507922.60</td>\n",
       "      <td>2505506.51</td>\n",
       "      <td>2507856.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>35954423.18</td>\n",
       "      <td>35884285.68</td>\n",
       "      <td>37065236.73</td>\n",
       "      <td>36992277.41</td>\n",
       "      <td>36983678.76</td>\n",
       "      <td>36987703.12</td>\n",
       "      <td>36995890.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Day_of_week      Friday      Monday    Saturday      Sunday    Thursday  \\\n",
       "count            482.00      482.00      482.00      482.00      482.00   \n",
       "mean         1977711.91  1974320.14  2037390.65  2031683.84  2035321.89   \n",
       "std          3394740.05  3401518.74  3504504.94  3503057.65  3495302.91   \n",
       "min              736.35      366.18      714.38      478.82      774.35   \n",
       "25%            14325.40     6019.41    14262.58     7912.57    14818.00   \n",
       "50%           878459.39   879843.93   892638.23   891524.78   909133.43   \n",
       "75%          2434867.57  2429649.42  2506775.21  2493596.83  2507922.60   \n",
       "max         35954423.18 35884285.68 37065236.73 36992277.41 36983678.76   \n",
       "\n",
       "Day_of_week     Tuesday   Wednesday  \n",
       "count            482.00      482.00  \n",
       "mean         2038255.29  2038710.93  \n",
       "std          3502216.72  3502971.78  \n",
       "min              714.88      721.82  \n",
       "25%            13676.63    14831.29  \n",
       "50%           906872.93   908389.62  \n",
       "75%          2505506.51  2507856.30  \n",
       "max         36987703.12 36995890.29  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtp = dtp.reset_index()\n",
    "dtp['Day_of_week'] = pd.to_datetime(dtp['Date'], format = '%m/%d/%Y').apply(lambda row: row.strftime(\"%A\"))\n",
    "\n",
    "dtp_sum = dtp.groupby(['Day_of_week','Station'])['Total_throughput'].sum().reset_index()\n",
    "pivot = dtp_sum.pivot(index='Station', columns='Day_of_week', values = 'Total_throughput')\n",
    "\n",
    "monday = pivot['Monday'].sort_values(ascending=False).index.values\n",
    "tuesday = pivot['Tuesday'].sort_values(ascending=False).index.values\n",
    "wednesday = pivot['Wednesday'].sort_values(ascending=False).index.values\n",
    "thursday = pivot['Thursday'].sort_values(ascending=False).index.values\n",
    "friday = pivot['Friday'].sort_values(ascending=False).index.values\n",
    "saturday = pivot['Saturday'].sort_values(ascending=False).index.values\n",
    "sunday = pivot['Sunday'].sort_values(ascending=False).index.values\n",
    "\n",
    "df = pd.DataFrame({'Monday': monday,\n",
    "                  'Tuesday': tuesday,\n",
    "                  'Wednesday': wednesday,\n",
    "                  'Thursday': thursday,\n",
    "                  'Friday': friday,\n",
    "                  'Saturday': saturday,\n",
    "                  'Sunday': sunday})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dtp['Day_of_week'] = #(pd.to_datetime(dtp.reset_index()['Date'], format = '%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dtp_sum.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtp_mean = dtp.groupby(['Day_of_week','Station'])['Total_throughput'].mean().reset_index()\n",
    "pivot = dtp_mean.pivot(index='Station', columns='Day_of_week', values = 'Total_throughput')\n",
    "\n",
    "monday = pivot['Monday'].sort_values(ascending=False).index.values\n",
    "tuesday = pivot['Tuesday'].sort_values(ascending=False).index.values\n",
    "wednesday = pivot['Wednesday'].sort_values(ascending=False).index.values\n",
    "thursday = pivot['Thursday'].sort_values(ascending=False).index.values\n",
    "friday = pivot['Friday'].sort_values(ascending=False).index.values\n",
    "saturday = pivot['Saturday'].sort_values(ascending=False).index.values\n",
    "sunday = pivot['Sunday'].sort_values(ascending=False).index.values\n",
    "\n",
    "df = pd.DataFrame({'Monday': monday,\n",
    "                  'Tuesday': tuesday,\n",
    "                  'Wednesday': wednesday,\n",
    "                  'Thursday': thursday,\n",
    "                  'Friday': friday,\n",
    "                  'Saturday': saturday,\n",
    "                  'Sunday': sunday})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivot.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivot['Monday'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivot.index.values\n",
    "pivot.loc['42 ST-GROAD CNTRL', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivot['Friday'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivot['Monday'].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dfutil.save_dataframe_as_pickle(df,'ranked_stations_by_day.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "Day of the week - 7 days \n",
    "- index'd by rank\n",
    "- names of stations \n",
    "- each column is a time of the day\n",
    "\n",
    "map of morning, afternoon, evening\n",
    "     for each day of week\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hourly Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# htp_mean = htp.groupby(['Station', 'Datetime']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtp['Day_of_week'] = dtp['Datetime'].apply(lambda row: row.strftime(\"%A\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htp['Day_of_week'] = htp['Datetime'].apply(lambda row: row.strftime(\"%A\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htp['Hour'] = htp['Datetime'].apply(lambda row: row.strftime(\"%-I%p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eight_am_mask = (htp['Hour'] == '7AM') | (htp['Hour'] == '8AM') | (htp['Hour'] == '9AM') | (htp['Hour'] == '10AM')\n",
    "four_pm_mask = (htp['Hour'] == '4PM') | (htp['Hour'] == '5PM') | (htp['Hour'] == '6PM') | (htp['Hour'] == '7PM') | (htp['Hour'] == '8PM')\n",
    "twelve_pm_mask = (htp['Hour'] == '11AM') | (htp['Hour'] == '12PM') | (htp['Hour'] == '1PM') | (htp['Hour'] == '2PM') | (htp['Hour']) == '3PM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htp_8am = htp.loc[eight_am_mask,:].groupby(['Station','Day_of_week','Hour']).mean()\n",
    "htp_12pm = htp.loc[twelve_pm_mask,:].groupby(['Station','Day_of_week','Hour']).mean()\n",
    "htp_4pm = htp.loc[four_pm_mask,:].groupby(['Station','Day_of_week','Hour']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htp_8am_station_mean = htp_8am.reset_index().groupby(['Station','Day_of_week']).mean().reset_index()\n",
    "pivot = (htp_8am_station_mean\n",
    "         .pivot(index='Station', columns='Day_of_week', values = 'Throughput')\n",
    "         .apply(lambda row: abs(row)))\n",
    "\n",
    "\n",
    "monday = pivot['Monday'].sort_values(ascending=False).index.values\n",
    "tuesday = pivot['Tuesday'].sort_values(ascending=False).index.values\n",
    "wednesday = pivot['Wednesday'].sort_values(ascending=False).index.values\n",
    "thursday = pivot['Thursday'].sort_values(ascending=False).index.values\n",
    "friday = pivot['Friday'].sort_values(ascending=False).index.values\n",
    "saturday = pivot['Saturday'].sort_values(ascending=False).index.values\n",
    "sunday = pivot['Sunday'].sort_values(ascending=False).index.values\n",
    "\n",
    "e8_am_df = pd.DataFrame({'Monday': monday,\n",
    "                  'Tuesday': tuesday,\n",
    "                  'Wednesday': wednesday,\n",
    "                  'Thursday': thursday,\n",
    "                  'Friday': friday,\n",
    "                  'Saturday': saturday,\n",
    "                  'Sunday': sunday})\n",
    "\n",
    "# dfutil.save_dataframe_as_pickle(e8_am_df,'8am_hourly_tp.pickle')\n",
    "\n",
    "e8_am_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = (pivot > 20000)\n",
    "pivot[mask].dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_149st = htp['Station'] == '149 ST-3 AVE'\n",
    "_g1000 = htp[_149st]['Throughput'] > 1000\n",
    "\n",
    "# _g1000\n",
    "_g1000\n",
    "# htp[_g1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htp[_g1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htp_12pm_station_mean = htp_12pm.reset_index().groupby(['Station','Day_of_week']).mean().reset_index()\n",
    "pivot = htp_12pm_station_mean.pivot(index='Station', columns='Day_of_week', values = 'Throughput')\n",
    "\n",
    "monday = pivot['Monday'].sort_values(ascending=False).index.values\n",
    "tuesday = pivot['Tuesday'].sort_values(ascending=False).index.values\n",
    "wednesday = pivot['Wednesday'].sort_values(ascending=False).index.values\n",
    "thursday = pivot['Thursday'].sort_values(ascending=False).index.values\n",
    "friday = pivot['Friday'].sort_values(ascending=False).index.values\n",
    "saturday = pivot['Saturday'].sort_values(ascending=False).index.values\n",
    "sunday = pivot['Sunday'].sort_values(ascending=False).index.values\n",
    "\n",
    "t12_pm_df = pd.DataFrame({'Monday': monday,\n",
    "                  'Tuesday': tuesday,\n",
    "                  'Wednesday': wednesday,\n",
    "                  'Thursday': thursday,\n",
    "                  'Friday': friday,\n",
    "                  'Saturday': saturday,\n",
    "                  'Sunday': sunday})\n",
    "\n",
    "# dfutil.save_dataframe_as_pickle(t12_pm_df,'12pm_hourly_tp.pickle')\n",
    "\n",
    "t12_pm_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htp_4pm_station_mean = htp_4pm.reset_index().groupby(['Station','Day_of_week']).mean().reset_index()\n",
    "pivot = htp_4pm_station_mean.pivot(index='Station', columns='Day_of_week', values = 'Throughput')\n",
    "\n",
    "monday = pivot['Monday'].sort_values(ascending=False).index.values\n",
    "tuesday = pivot['Tuesday'].sort_values(ascending=False).index.values\n",
    "wednesday = pivot['Wednesday'].sort_values(ascending=False).index.values\n",
    "thursday = pivot['Thursday'].sort_values(ascending=False).index.values\n",
    "friday = pivot['Friday'].sort_values(ascending=False).index.values\n",
    "saturday = pivot['Saturday'].sort_values(ascending=False).index.values\n",
    "sunday = pivot['Sunday'].sort_values(ascending=False).index.values\n",
    "\n",
    "f4_pm_df = pd.DataFrame({'Monday': monday,\n",
    "                  'Tuesday': tuesday,\n",
    "                  'Wednesday': wednesday,\n",
    "                  'Thursday': thursday,\n",
    "                  'Friday': friday,\n",
    "                  'Saturday': saturday,\n",
    "                  'Sunday': sunday})\n",
    "\n",
    "# dfutil.save_dataframe_as_pickle(f4_pm_df,'4pm_hourly_tp.pickle')\n",
    "\n",
    "f4_pm_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htp_8am.groupby(['Day_of_week']).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration \n",
    "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The column names contain unneeded whitespace.\n",
    "df1.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The dataframe also lacks a timeseries.\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Strip whitespace from column names\n",
    "df1.columns = [s.strip() for s in df1.columns.values]\n",
    "\n",
    "# Create datetime column with datetime datatype\n",
    "df1['Datetime'] = pd.to_datetime(df1.DATE + ' ' + df1.TIME,\n",
    "                                 format = '%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "df1.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chain methods together to further clean data:\n",
    "    # drop old date and time columns\n",
    "    # rename columns\n",
    "    \n",
    "dict_col_rename = {'C/A' : 'C_A', 'UNIT' : 'Unit', 'STATION' : 'Station', 'LINENAME' : 'Linename',\n",
    "                  'DIVISION' : 'Division', 'DESC' : 'Desc', 'ENTRIES' : 'Entries', 'EXITS' : 'Exits',\n",
    "                  'DATE' : 'Date'}    \n",
    "\n",
    "df2 = (df1\n",
    "       #.drop('DATE', axis = 1)\n",
    "       .drop('TIME', axis = 1)\n",
    "       .rename(columns = dict_col_rename)\n",
    "      )\n",
    "\n",
    "df2.iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Erroneous Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check uniqueness of rows/indexes by getting counts.\n",
    "(df2\n",
    " .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Datetime'])\n",
    " .count() #.Entries.count()\n",
    " .reset_index()\n",
    " .sort_values('Entries', ascending = False)\n",
    " .iloc[:5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On 3/25, we don't seem to have two entries for same time, but let's take a look anyway.\n",
    "\n",
    "mask = ((df2[\"C_A\"] == \"A002\") & \n",
    "(df2[\"Unit\"] == \"R051\") & \n",
    "(df2[\"SCP\"] == \"02-00-00\") & \n",
    "(df2[\"Station\"] == \"59 ST\") &\n",
    "(df2[\"Datetime\"].dt.date == datetime.datetime(2017, 3, 25).date()))\n",
    "df2[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.Desc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Questions for the future, if there is time:\n",
    "    # Are there other values of DESC?\n",
    "    # Are there other fields to check for odd values?\n",
    "\n",
    "# Drop duplicates.\n",
    "df_no_dupe = df2.drop_duplicates(subset=['C_A', 'Unit', 'SCP', 'Station', 'Datetime'])\n",
    "\n",
    "# Check uniqueness again after data cleaning to confirm cleanness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_no_dupe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Entries and Exits per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_daily_entries = (df_no_dupe\n",
    "            .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Date'])\n",
    "            .Entries\n",
    "            .first()\n",
    "            .reset_index()\n",
    "           )\n",
    "\n",
    "df_daily_exits = (df_no_dupe\n",
    "            .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Date'])\n",
    "            .Exits\n",
    "            .first()\n",
    "            .reset_index()\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the differences by day\n",
    "df_daily_entries[[\"Prev_date\", \"Prev_entries\"]] = (df_daily_entries\n",
    "                                                       .groupby([\"C_A\", \"Unit\", \"SCP\", \"Station\"])[\"Date\", \"Entries\"]\n",
    "                                                       .transform(lambda grp: grp.shift(1)))\n",
    "\n",
    "df_daily_exits[[\"Prev_date\", \"Prev_exits\"]]   = (df_daily_exits\n",
    "                                                       .groupby([\"C_A\", \"Unit\", \"SCP\", \"Station\"])[\"Date\", \"Exits\"]\n",
    "                                                       .transform(lambda grp: grp.shift(1)))\n",
    "\n",
    "# Drop all the null values generated above\n",
    "df_daily_entries.dropna(subset=[\"Prev_date\"], axis=0, inplace=True)\n",
    "df_daily_exits.dropna(subset=[\"Prev_date\"], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_daily_entries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for any counters that have been reversed\n",
    "df_daily_entries[df_daily_entries[\"Entries\"] < df_daily_entries[\"Prev_entries\"]].head()\n",
    "\n",
    "# WTC: Is this something that can be solved by sorting before applying the transform above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### HAVE NOT EDITED YET\n",
    "\n",
    "# Pick a value from one of the counters reversed above & check for it \n",
    "# What's the deal with counter being in reverse\n",
    "# mask = ((turnstiles_df[\"C/A\"] == \"A011\") & \n",
    "# (turnstiles_df[\"UNIT\"] == \"R080\") & \n",
    "# (turnstiles_df[\"SCP\"] == \"01-00-00\") & \n",
    "# (turnstiles_df[\"STATION\"] == \"57 ST-7 AV\") &\n",
    "# (turnstiles_df[\"DATE_TIME\"].dt.date == datetime.datetime(2016, 8, 27).date()))\n",
    "# turnstiles_df[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's see how many stations have this problem\n",
    "\n",
    "(df_daily_entries[df_daily_entries[\"Entries\"] < df_daily_entries[\"Prev_entries\"]]\n",
    "    .groupby([\"C_A\", \"Unit\", \"SCP\", \"Station\"])\n",
    "    .size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def get_daily_counts(row, max_counter, cols):\n",
    "#     counter = row[cols[0]] - row[cols[1]]\n",
    "#     if counter < 0:\n",
    "#         # May be counter is reversed?\n",
    "#         counter = -counter\n",
    "#     if counter > max_counter:\n",
    "#         print(row[cols[0]], row[cols[1]])\n",
    "#         counter = min(row[cols[0]], row[cols[1]])\n",
    "#     if counter > max_counter:\n",
    "#         # Check it again to make sure we are not giving a counter that's too big\n",
    "#         return 0\n",
    "#     return counter\n",
    "\n",
    "# If counter is > 1Million, then the counter might have been reset.  \n",
    "# Just set it to zero as different counters have different cycle limits\n",
    "df_daily_entries[\"Daily_Entries\"] = df_daily_entries.apply(get_daily_counts, axis=1, args=(1000000, ['Entries', 'Prev_entries']))\n",
    "df_daily_exits[\"Daily_Exits\"] = df_daily_exits.apply(get_daily_counts, axis=1, args=(1000000, ['Exits', 'Prev_exits']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_daily_entries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_daily_exits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_daily = pd.merge(df_daily_entries, df_daily_exits, on=['C_A','Unit','SCP', 'Station', 'Date', 'Prev_date'])\n",
    "df_daily['Total_throughput'] = df_daily['Daily_Entries'] + df_daily['Daily_Exits']\n",
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df_daily\n",
    " .groupby(['Station', 'Date'])\n",
    " .sum()\n",
    "#  .sort_values(by=['Total_throughput'], ascending=False)\n",
    " .loc[:,['Daily_Entries', 'Daily_Exits', 'Total_throughput']]\n",
    "#  .frame()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Entries and Exits per Hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use concat (as a join) to fix (\"de-cumulate\") the columns Entries and Exits\n",
    "\n",
    "df_shift = (df_no_dupe\n",
    "            .copy()\n",
    "            .drop('Linename', axis = 1)\n",
    "            .drop('Division', axis = 1)\n",
    "           )\n",
    "\n",
    "df_shift[['Datetime_Prev', 'Entries_Prev', 'Exits_Prev']] = (df_shift\n",
    "            .groupby(['C_A', 'Unit', 'SCP', 'Station'])['Datetime', 'Entries', 'Exits']\n",
    "            .transform(lambda grp: grp.shift(1)))\n",
    "\n",
    "df_shift.head()\n",
    "\n",
    "\n",
    "# Legacy\n",
    "\n",
    "# df_shift.columns\n",
    "# df_shift['Datetime_Prev', 'Entries_Prev', 'Exits_Prev'] = (\n",
    "#     df_no_dupe#[['C_A', 'Unit', 'SCP', 'Station', 'Datetime', 'Entries', 'Exits']]\n",
    "#             .groupby(['C_A', 'Unit', 'SCP', 'Station'])['Datetime', 'Entries', 'Exits']\n",
    "#             #.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])[\"DATE\", \"ENTRIES\"]\n",
    "#             .transform(lambda grp: grp.shift(1))\n",
    "#             #.shift(periods = 1)\n",
    "#             #.rename(columns = {'Entries' : 'Entries_Shift', 'Exits' : 'Exits_Shift', \n",
    "#             #                   'Datetime' : 'Prev_datetime'})\n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_shift['Entries'] = df_shift['Entries'] - df_shift['Entries_Prev']\n",
    "df_shift['Exits'] = df_shift['Exits'] - df_shift['Exits_Prev']\n",
    "df_shift = df_shift.dropna(how = 'any')\n",
    "\n",
    "df_shift.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Challenge 3 - Total Daily Entries\n",
    "#df3or4['Datetime'].dt.date == datetime.datetime(YYYY, MM, DD).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_daily_counts(row, max_counter):\n",
    "#     counter = abs(row[\"ENTRIES\"] - row[\"PREV_ENTRIES\"])\n",
    "    \n",
    "#     if counter > max_counter:\n",
    "#         print(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "#         return 0\n",
    "#     return counter\n",
    "\n",
    "# # If counter is > 1Million, then the counter might have been reset.  \n",
    "# # Just set it to zero as different counters have different cycle limits\n",
    "# _ = turnstiles_daily.apply(get_daily_counts, axis=1, max_counter=1000000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
