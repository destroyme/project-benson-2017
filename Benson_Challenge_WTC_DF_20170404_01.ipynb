{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "\n",
    "import MP_functions as dfutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing & Loading Data\n",
    "\n",
    "Make sure to unzip the pickles.zip into the root folder for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from load_pickles import df as pickle\n",
    "df = dfutil.open_dataframe_pickle('MTA_DATA_SPRING_2014_to_2016_FULL.pickle')\n",
    "dtp = dfutil.open_dataframe_pickle('daily_throughput.pickle')\n",
    "htp = dfutil.open_dataframe_pickle('hourly_throughput.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_daily_counts(row, max_counter, cols):\n",
    "    \"\"\"\n",
    "    cols - a list of columns to compute the difference from with format [x, y] = x-y\n",
    "    \"\"\"\n",
    "    counter = row[cols[0]] - row[cols[1]]\n",
    "    if counter < 0:\n",
    "        # May be counter is reversed?\n",
    "        counter = -counter\n",
    "    if counter > max_counter:\n",
    "#         print(row[cols[0]], row[cols[1]])\n",
    "        counter = min(row[cols[0]], row[cols[1]])\n",
    "    if counter > max_counter:\n",
    "        # Check it again to make sure we are not giving a counter that's too big\n",
    "        return 0\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleanData(frame):\n",
    "    # Strip whitespace from column names\n",
    "    frame.columns = [s.strip() for s in frame.columns.values]\n",
    "\n",
    "    # Create datetime column with datetime datatype\n",
    "    frame['Datetime'] = pd.to_datetime(frame.DATE + ' ' + frame.TIME,\n",
    "                                        format = '%m/%d/%Y %H:%M:%S')\n",
    "    frame['Day_of_week'] = frame['Datetime'].apply(lambda row: row.strftime(\"%A\"))\n",
    "    \n",
    "    # Chain methods together to further clean data:\n",
    "        # drop old date and time columns\n",
    "        # rename columns\n",
    "    \n",
    "    dict_col_rename = {'C/A' : 'C_A', 'UNIT' : 'Unit', 'STATION' : 'Station', 'LINENAME' : 'Linename',\n",
    "                      'DIVISION' : 'Division', 'DESC' : 'Desc', 'ENTRIES' : 'Entries', 'EXITS' : 'Exits',\n",
    "                      'DATE' : 'Date'}    \n",
    "\n",
    "    frame2 = frame.rename(columns = dict_col_rename)\n",
    "    \n",
    "    # Check uniqueness of rows/indexes by getting counts.\n",
    "    (frame2\n",
    "     .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Datetime'])\n",
    "     .count() #.Entries.count()\n",
    "     .reset_index()\n",
    "     .sort_values('Entries', ascending = False)\n",
    "    )\n",
    "    \n",
    "    # Drop duplicates.\n",
    "    return frame2.drop_duplicates(subset=['C_A', 'Unit', 'SCP', 'Station', 'Datetime'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcDailyThroughput(frame):\n",
    "    \n",
    "    # group daily entries and daily exits\n",
    "    daily_entries = (frame\n",
    "                      .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Date'])\n",
    "                      .Entries\n",
    "                      .first()\n",
    "                      .reset_index()\n",
    "                    )\n",
    "\n",
    "    daily_exits = (frame\n",
    "                    .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Date'])\n",
    "                    .Exits\n",
    "                    .first()\n",
    "                    .reset_index()\n",
    "                   )\n",
    "    \n",
    "    # Calculate the differences by day\n",
    "    daily_entries[[\"Prev_date\", \"Prev_entries\"]] = (daily_entries\n",
    "                                                     .groupby([\"C_A\", \"Unit\", \"SCP\", \"Station\"])[\"Date\", \"Entries\"]\n",
    "                                                     .transform(lambda grp: grp.shift(1)))\n",
    "\n",
    "    daily_exits[[\"Prev_date\", \"Prev_exits\"]]   = (daily_exits\n",
    "                                                   .groupby([\"C_A\", \"Unit\", \"SCP\", \"Station\"])[\"Date\", \"Exits\"]\n",
    "                                                   .transform(lambda grp: grp.shift(1)))\n",
    "\n",
    "    # Drop all the null values generated above\n",
    "    daily_entries.dropna(subset=[\"Prev_date\"], axis=0, inplace=True)\n",
    "    daily_exits.dropna(subset=[\"Prev_date\"], axis=0, inplace=True)\n",
    "\n",
    "\n",
    "    daily_entries[\"Daily_Entries\"] = daily_entries.apply(get_daily_counts, axis=1, args=(1000000, ['Entries', 'Prev_entries']))\n",
    "    daily_exits[\"Daily_Exits\"] = daily_exits.apply(get_daily_counts, axis=1, args=(1000000, ['Exits', 'Prev_exits']))\n",
    "    \n",
    "    daily = pd.merge(daily_entries, daily_exits, on=['C_A','Unit','SCP', 'Station', 'Date', 'Prev_date'])\n",
    "    daily['Total_throughput'] = daily['Daily_Entries'] + daily['Daily_Exits']\n",
    "    \n",
    "    return (daily\n",
    "             .groupby(['Station', 'Date'])\n",
    "             .sum()\n",
    "            #  .sort_values(by=['Total_throughput'], ascending=False)\n",
    "             .loc[:,['Daily_Entries', 'Daily_Exits', 'Total_throughput']]\n",
    "            #  .frame()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcHourThroughput(frame):\n",
    "    shift = frame.copy()\n",
    "\n",
    "    shift[['Datetime_Prev', 'Entries_Prev', 'Exits_Prev']] = (shift\n",
    "                .groupby(['C_A', 'Unit', 'SCP', 'Station'])['Datetime', 'Entries', 'Exits']\n",
    "                .transform(lambda grp: grp.shift(1)))\n",
    "    \n",
    "    shift['Entries'] = shift['Entries'] - shift['Entries_Prev']\n",
    "    shift['Exits'] = shift['Exits'] - shift['Exits_Prev']\n",
    "    shift = shift.dropna(how = 'any')\n",
    "    \n",
    "    shift['Throughput'] = shift['Entries'] + shift['Exits']\n",
    "    \n",
    "    return shift.loc[:,['Station','Datetime','Throughput']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make note to save and open pickles here:\n",
    "# dfutil.save_dataframe_as_pickle(df,'MTA_DATA_SPRING_2014_to_2016_FULL.pickle')\n",
    "# df_pickle = dfutil.open_dataframe_pickle('MTA_DATA_SPRING_2014_to_2016_FULL.pickle') # returns a df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To find hour through put \n",
    "# test_df3.groupby(['Station', 'Datetime']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_A</th>\n",
       "      <th>Unit</th>\n",
       "      <th>SCP</th>\n",
       "      <th>Station</th>\n",
       "      <th>Linename</th>\n",
       "      <th>Division</th>\n",
       "      <th>Date</th>\n",
       "      <th>TIME</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Entries</th>\n",
       "      <th>Exits</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>BMT</td>\n",
       "      <td>06/18/2016</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5704958</td>\n",
       "      <td>1934814</td>\n",
       "      <td>2016-06-18 00:00:00</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>BMT</td>\n",
       "      <td>06/18/2016</td>\n",
       "      <td>04:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5704958</td>\n",
       "      <td>1934829</td>\n",
       "      <td>2016-06-18 04:00:00</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>BMT</td>\n",
       "      <td>06/18/2016</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5704958</td>\n",
       "      <td>1934886</td>\n",
       "      <td>2016-06-18 08:00:00</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>BMT</td>\n",
       "      <td>06/18/2016</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5704958</td>\n",
       "      <td>1934993</td>\n",
       "      <td>2016-06-18 12:00:00</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456</td>\n",
       "      <td>BMT</td>\n",
       "      <td>06/18/2016</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>5704958</td>\n",
       "      <td>1935069</td>\n",
       "      <td>2016-06-18 16:00:00</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C_A  Unit       SCP Station Linename Division        Date      TIME  \\\n",
       "0  A002  R051  02-00-00   59 ST   NQR456      BMT  06/18/2016  00:00:00   \n",
       "1  A002  R051  02-00-00   59 ST   NQR456      BMT  06/18/2016  04:00:00   \n",
       "2  A002  R051  02-00-00   59 ST   NQR456      BMT  06/18/2016  08:00:00   \n",
       "3  A002  R051  02-00-00   59 ST   NQR456      BMT  06/18/2016  12:00:00   \n",
       "4  A002  R051  02-00-00   59 ST   NQR456      BMT  06/18/2016  16:00:00   \n",
       "\n",
       "      Desc  Entries    Exits            Datetime Day_of_week  \n",
       "0  REGULAR  5704958  1934814 2016-06-18 00:00:00    Saturday  \n",
       "1  REGULAR  5704958  1934829 2016-06-18 04:00:00    Saturday  \n",
       "2  REGULAR  5704958  1934886 2016-06-18 08:00:00    Saturday  \n",
       "3  REGULAR  5704958  1934993 2016-06-18 12:00:00    Saturday  \n",
       "4  REGULAR  5704958  1935069 2016-06-18 16:00:00    Saturday  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Throughput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-06-18 04:00:00</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-06-18 08:00:00</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-06-18 12:00:00</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-06-18 16:00:00</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59 ST</td>\n",
       "      <td>2016-06-18 20:00:00</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Station            Datetime  Throughput\n",
       "1   59 ST 2016-06-18 04:00:00        15.0\n",
       "2   59 ST 2016-06-18 08:00:00        57.0\n",
       "3   59 ST 2016-06-18 12:00:00       107.0\n",
       "4   59 ST 2016-06-18 16:00:00        76.0\n",
       "5   59 ST 2016-06-18 20:00:00        63.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Throughput</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Station</th>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1 AVE</th>\n",
       "      <th>2015-02-28 03:00:00</th>\n",
       "      <td>-642981.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-28 07:00:00</th>\n",
       "      <td>1008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-28 11:00:00</th>\n",
       "      <td>4564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-28 15:00:00</th>\n",
       "      <td>8289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-28 19:00:00</th>\n",
       "      <td>10733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-28 23:00:00</th>\n",
       "      <td>10352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-01 03:00:00</th>\n",
       "      <td>4968.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-01 07:00:00</th>\n",
       "      <td>1010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-01 11:00:00</th>\n",
       "      <td>3297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-01 15:00:00</th>\n",
       "      <td>7884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-01 19:00:00</th>\n",
       "      <td>8695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-01 23:00:00</th>\n",
       "      <td>5538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-02 03:00:00</th>\n",
       "      <td>1412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-02 07:00:00</th>\n",
       "      <td>1930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-02 11:00:00</th>\n",
       "      <td>13928.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-02 15:00:00</th>\n",
       "      <td>7776.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-02 19:00:00</th>\n",
       "      <td>14161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-02 23:00:00</th>\n",
       "      <td>9171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 03:00:00</th>\n",
       "      <td>1603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 07:00:00</th>\n",
       "      <td>2045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 11:00:00</th>\n",
       "      <td>14351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 15:00:00</th>\n",
       "      <td>7893.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 19:00:00</th>\n",
       "      <td>15905.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-03 23:00:00</th>\n",
       "      <td>10250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-04 03:00:00</th>\n",
       "      <td>1665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-04 07:00:00</th>\n",
       "      <td>1950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-04 11:00:00</th>\n",
       "      <td>14268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-04 15:00:00</th>\n",
       "      <td>7566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-04 19:00:00</th>\n",
       "      <td>14502.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-04 23:00:00</th>\n",
       "      <td>9907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">ZEREGA AVE</th>\n",
       "      <th>2016-06-20 01:00:00</th>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-20 05:00:00</th>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-20 09:00:00</th>\n",
       "      <td>1462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-20 13:00:00</th>\n",
       "      <td>804.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-20 17:00:00</th>\n",
       "      <td>1093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-20 21:00:00</th>\n",
       "      <td>1092.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-21 01:00:00</th>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-21 05:00:00</th>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-21 09:00:00</th>\n",
       "      <td>1504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-21 13:00:00</th>\n",
       "      <td>786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-21 17:00:00</th>\n",
       "      <td>1096.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-21 21:00:00</th>\n",
       "      <td>1170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-22 01:00:00</th>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-22 05:00:00</th>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-22 09:00:00</th>\n",
       "      <td>1477.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-22 13:00:00</th>\n",
       "      <td>794.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-22 17:00:00</th>\n",
       "      <td>1074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-22 21:00:00</th>\n",
       "      <td>1174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-23 01:00:00</th>\n",
       "      <td>425.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-23 05:00:00</th>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-23 09:00:00</th>\n",
       "      <td>1515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-23 13:00:00</th>\n",
       "      <td>737.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-23 17:00:00</th>\n",
       "      <td>1046.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-23 21:00:00</th>\n",
       "      <td>1114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-24 01:00:00</th>\n",
       "      <td>349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-24 05:00:00</th>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-24 09:00:00</th>\n",
       "      <td>1478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-24 13:00:00</th>\n",
       "      <td>815.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-24 17:00:00</th>\n",
       "      <td>1108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-24 21:00:00</th>\n",
       "      <td>1113.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>956098 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Throughput\n",
       "Station    Datetime                       \n",
       "1 AVE      2015-02-28 03:00:00   -642981.0\n",
       "           2015-02-28 07:00:00      1008.0\n",
       "           2015-02-28 11:00:00      4564.0\n",
       "           2015-02-28 15:00:00      8289.0\n",
       "           2015-02-28 19:00:00     10733.0\n",
       "           2015-02-28 23:00:00     10352.0\n",
       "           2015-03-01 03:00:00      4968.0\n",
       "           2015-03-01 07:00:00      1010.0\n",
       "           2015-03-01 11:00:00      3297.0\n",
       "           2015-03-01 15:00:00      7884.0\n",
       "           2015-03-01 19:00:00      8695.0\n",
       "           2015-03-01 23:00:00      5538.0\n",
       "           2015-03-02 03:00:00      1412.0\n",
       "           2015-03-02 07:00:00      1930.0\n",
       "           2015-03-02 11:00:00     13928.0\n",
       "           2015-03-02 15:00:00      7776.0\n",
       "           2015-03-02 19:00:00     14161.0\n",
       "           2015-03-02 23:00:00      9171.0\n",
       "           2015-03-03 03:00:00      1603.0\n",
       "           2015-03-03 07:00:00      2045.0\n",
       "           2015-03-03 11:00:00     14351.0\n",
       "           2015-03-03 15:00:00      7893.0\n",
       "           2015-03-03 19:00:00     15905.0\n",
       "           2015-03-03 23:00:00     10250.0\n",
       "           2015-03-04 03:00:00      1665.0\n",
       "           2015-03-04 07:00:00      1950.0\n",
       "           2015-03-04 11:00:00     14268.0\n",
       "           2015-03-04 15:00:00      7566.0\n",
       "           2015-03-04 19:00:00     14502.0\n",
       "           2015-03-04 23:00:00      9907.0\n",
       "...                                    ...\n",
       "ZEREGA AVE 2016-06-20 01:00:00       272.0\n",
       "           2016-06-20 05:00:00       133.0\n",
       "           2016-06-20 09:00:00      1462.0\n",
       "           2016-06-20 13:00:00       804.0\n",
       "           2016-06-20 17:00:00      1093.0\n",
       "           2016-06-20 21:00:00      1092.0\n",
       "           2016-06-21 01:00:00       404.0\n",
       "           2016-06-21 05:00:00       129.0\n",
       "           2016-06-21 09:00:00      1504.0\n",
       "           2016-06-21 13:00:00       786.0\n",
       "           2016-06-21 17:00:00      1096.0\n",
       "           2016-06-21 21:00:00      1170.0\n",
       "           2016-06-22 01:00:00       365.0\n",
       "           2016-06-22 05:00:00       142.0\n",
       "           2016-06-22 09:00:00      1477.0\n",
       "           2016-06-22 13:00:00       794.0\n",
       "           2016-06-22 17:00:00      1074.0\n",
       "           2016-06-22 21:00:00      1174.0\n",
       "           2016-06-23 01:00:00       425.0\n",
       "           2016-06-23 05:00:00       138.0\n",
       "           2016-06-23 09:00:00      1515.0\n",
       "           2016-06-23 13:00:00       737.0\n",
       "           2016-06-23 17:00:00      1046.0\n",
       "           2016-06-23 21:00:00      1114.0\n",
       "           2016-06-24 01:00:00       349.0\n",
       "           2016-06-24 05:00:00       134.0\n",
       "           2016-06-24 09:00:00      1478.0\n",
       "           2016-06-24 13:00:00       815.0\n",
       "           2016-06-24 17:00:00      1108.0\n",
       "           2016-06-24 21:00:00      1113.0\n",
       "\n",
       "[956098 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htp.groupby(['Station', 'Datetime']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dtp['Day_of_week'] = #(pd.to_datetime(dtp.reset_index()['Date'], format = '%m/%d/%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtp = dtp.reset_index()\n",
    "dtp['Day_of_week'] = pd.to_datetime(dtp['Date'], format = '%m/%d/%Y').apply(lambda row: row.strftime(\"%A\"))\n",
    "\n",
    "dtp_sum = dtp.groupby(['Day_of_week','Station'])['Total_throughput'].sum().reset_index()\n",
    "pivot = dtp_sum.pivot(index='Station', columns='Day_of_week', values = 'Total_throughput')\n",
    "\n",
    "monday = pivot['Monday'].sort_values(ascending=False).index.values\n",
    "tuesday = pivot['Tuesday'].sort_values(ascending=False).index.values\n",
    "wednesday = pivot['Wednesday'].sort_values(ascending=False).index.values\n",
    "thursday = pivot['Thursday'].sort_values(ascending=False).index.values\n",
    "friday = pivot['Friday'].sort_values(ascending=False).index.values\n",
    "saturday = pivot['Saturday'].sort_values(ascending=False).index.values\n",
    "sunday = pivot['Sunday'].sort_values(ascending=False).index.values\n",
    "\n",
    "df = pd.DataFrame({'Monday': monday,\n",
    "                  'Tuesday': tuesday,\n",
    "                  'Wednesday': wednesday,\n",
    "                  'Thursday': thursday,\n",
    "                  'Friday': friday,\n",
    "                  'Saturday': saturday,\n",
    "                  'Sunday': sunday})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfutil.save_dataframe_as_pickle(df,'ranked_stations_by_day.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "Day of the week - 7 days \n",
    "- index'd by rank\n",
    "- names of stations \n",
    "- each column is a time of the day\n",
    "\n",
    "map of morning, afternoon, evening\n",
    "     for each day of week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Daily_Entries</th>\n",
       "      <th>Daily_Exits</th>\n",
       "      <th>Total_throughput</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Station</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">1 AVE</th>\n",
       "      <th>02/28/2015</th>\n",
       "      <td>2149122.0</td>\n",
       "      <td>341314.0</td>\n",
       "      <td>2490436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/28/2016</th>\n",
       "      <td>2153712.0</td>\n",
       "      <td>342328.0</td>\n",
       "      <td>2496040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02/29/2016</th>\n",
       "      <td>14018.0</td>\n",
       "      <td>15107.0</td>\n",
       "      <td>29125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/01/2015</th>\n",
       "      <td>2151936.0</td>\n",
       "      <td>342214.0</td>\n",
       "      <td>2494150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/01/2016</th>\n",
       "      <td>2156668.0</td>\n",
       "      <td>343143.0</td>\n",
       "      <td>2499811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/02/2015</th>\n",
       "      <td>2154140.0</td>\n",
       "      <td>342541.0</td>\n",
       "      <td>2496681.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/02/2016</th>\n",
       "      <td>2159107.0</td>\n",
       "      <td>343636.0</td>\n",
       "      <td>2502743.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/03/2015</th>\n",
       "      <td>2154068.0</td>\n",
       "      <td>342652.0</td>\n",
       "      <td>2496720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/03/2016</th>\n",
       "      <td>2158936.0</td>\n",
       "      <td>343655.0</td>\n",
       "      <td>2502591.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/04/2015</th>\n",
       "      <td>2150710.0</td>\n",
       "      <td>342596.0</td>\n",
       "      <td>2493306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/04/2016</th>\n",
       "      <td>2155632.0</td>\n",
       "      <td>343580.0</td>\n",
       "      <td>2499212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/05/2015</th>\n",
       "      <td>2150726.0</td>\n",
       "      <td>342514.0</td>\n",
       "      <td>2493240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/05/2016</th>\n",
       "      <td>2156535.0</td>\n",
       "      <td>343656.0</td>\n",
       "      <td>2500191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/06/2016</th>\n",
       "      <td>20011.0</td>\n",
       "      <td>21791.0</td>\n",
       "      <td>41802.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/07/2015</th>\n",
       "      <td>2146870.0</td>\n",
       "      <td>342550.0</td>\n",
       "      <td>2489420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/07/2016</th>\n",
       "      <td>2149822.0</td>\n",
       "      <td>343268.0</td>\n",
       "      <td>2493090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/08/2015</th>\n",
       "      <td>2145564.0</td>\n",
       "      <td>342297.0</td>\n",
       "      <td>2487861.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/08/2016</th>\n",
       "      <td>2150316.0</td>\n",
       "      <td>343194.0</td>\n",
       "      <td>2493510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/09/2015</th>\n",
       "      <td>2147206.0</td>\n",
       "      <td>342648.0</td>\n",
       "      <td>2489854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/09/2016</th>\n",
       "      <td>2151783.0</td>\n",
       "      <td>343643.0</td>\n",
       "      <td>2495426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/10/2015</th>\n",
       "      <td>2146387.0</td>\n",
       "      <td>342610.0</td>\n",
       "      <td>2488997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/10/2016</th>\n",
       "      <td>2151705.0</td>\n",
       "      <td>343552.0</td>\n",
       "      <td>2495257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/11/2015</th>\n",
       "      <td>2145743.0</td>\n",
       "      <td>342412.0</td>\n",
       "      <td>2488155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/11/2016</th>\n",
       "      <td>2152120.0</td>\n",
       "      <td>343393.0</td>\n",
       "      <td>2495513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/12/2015</th>\n",
       "      <td>2145805.0</td>\n",
       "      <td>342452.0</td>\n",
       "      <td>2488257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/12/2016</th>\n",
       "      <td>2151444.0</td>\n",
       "      <td>343677.0</td>\n",
       "      <td>2495121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/13/2015</th>\n",
       "      <td>2144862.0</td>\n",
       "      <td>342644.0</td>\n",
       "      <td>2487506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/13/2016</th>\n",
       "      <td>2149273.0</td>\n",
       "      <td>343645.0</td>\n",
       "      <td>2492918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/14/2015</th>\n",
       "      <td>2137977.0</td>\n",
       "      <td>342647.0</td>\n",
       "      <td>2480624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/14/2016</th>\n",
       "      <td>2140598.0</td>\n",
       "      <td>343245.0</td>\n",
       "      <td>2483843.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">ZEREGA AVE</th>\n",
       "      <th>06/11/2015</th>\n",
       "      <td>756273.0</td>\n",
       "      <td>705710.0</td>\n",
       "      <td>1461983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/11/2016</th>\n",
       "      <td>759119.0</td>\n",
       "      <td>708101.0</td>\n",
       "      <td>1467220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/12/2015</th>\n",
       "      <td>756613.0</td>\n",
       "      <td>705862.0</td>\n",
       "      <td>1462475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/12/2016</th>\n",
       "      <td>758034.0</td>\n",
       "      <td>707214.0</td>\n",
       "      <td>1465248.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/13/2015</th>\n",
       "      <td>755509.0</td>\n",
       "      <td>704946.0</td>\n",
       "      <td>1460455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/13/2016</th>\n",
       "      <td>756632.0</td>\n",
       "      <td>706040.0</td>\n",
       "      <td>1462672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/14/2015</th>\n",
       "      <td>755343.0</td>\n",
       "      <td>704754.0</td>\n",
       "      <td>1460097.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/14/2016</th>\n",
       "      <td>758022.0</td>\n",
       "      <td>707192.0</td>\n",
       "      <td>1465214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/15/2015</th>\n",
       "      <td>757055.0</td>\n",
       "      <td>706078.0</td>\n",
       "      <td>1463133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/15/2016</th>\n",
       "      <td>759716.0</td>\n",
       "      <td>708502.0</td>\n",
       "      <td>1468218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/16/2015</th>\n",
       "      <td>757361.0</td>\n",
       "      <td>706304.0</td>\n",
       "      <td>1463665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/16/2016</th>\n",
       "      <td>760171.0</td>\n",
       "      <td>708844.0</td>\n",
       "      <td>1469015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/17/2015</th>\n",
       "      <td>757753.0</td>\n",
       "      <td>706566.0</td>\n",
       "      <td>1464319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/17/2016</th>\n",
       "      <td>760479.0</td>\n",
       "      <td>709016.0</td>\n",
       "      <td>1469495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/18/2015</th>\n",
       "      <td>758014.0</td>\n",
       "      <td>706700.0</td>\n",
       "      <td>1464714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/18/2016</th>\n",
       "      <td>760688.0</td>\n",
       "      <td>709127.0</td>\n",
       "      <td>1469815.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/19/2015</th>\n",
       "      <td>758242.0</td>\n",
       "      <td>706811.0</td>\n",
       "      <td>1465053.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/19/2016</th>\n",
       "      <td>759717.0</td>\n",
       "      <td>708156.0</td>\n",
       "      <td>1467873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/20/2015</th>\n",
       "      <td>757393.0</td>\n",
       "      <td>706015.0</td>\n",
       "      <td>1463408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/20/2016</th>\n",
       "      <td>758461.0</td>\n",
       "      <td>707110.0</td>\n",
       "      <td>1465571.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/21/2015</th>\n",
       "      <td>757334.0</td>\n",
       "      <td>706385.0</td>\n",
       "      <td>1463719.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/21/2016</th>\n",
       "      <td>759965.0</td>\n",
       "      <td>708742.0</td>\n",
       "      <td>1468707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/22/2015</th>\n",
       "      <td>759091.0</td>\n",
       "      <td>708071.0</td>\n",
       "      <td>1467162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/22/2016</th>\n",
       "      <td>761784.0</td>\n",
       "      <td>710428.0</td>\n",
       "      <td>1472212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/23/2015</th>\n",
       "      <td>759371.0</td>\n",
       "      <td>708280.0</td>\n",
       "      <td>1467651.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/23/2016</th>\n",
       "      <td>762036.0</td>\n",
       "      <td>710701.0</td>\n",
       "      <td>1472737.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/24/2015</th>\n",
       "      <td>759738.0</td>\n",
       "      <td>708469.0</td>\n",
       "      <td>1468207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/24/2016</th>\n",
       "      <td>762407.0</td>\n",
       "      <td>710699.0</td>\n",
       "      <td>1473106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/25/2015</th>\n",
       "      <td>760005.0</td>\n",
       "      <td>708449.0</td>\n",
       "      <td>1468454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06/26/2015</th>\n",
       "      <td>2385.0</td>\n",
       "      <td>2152.0</td>\n",
       "      <td>4537.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89103 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Daily_Entries  Daily_Exits  Total_throughput\n",
       "Station    Date                                                    \n",
       "1 AVE      02/28/2015      2149122.0     341314.0         2490436.0\n",
       "           02/28/2016      2153712.0     342328.0         2496040.0\n",
       "           02/29/2016        14018.0      15107.0           29125.0\n",
       "           03/01/2015      2151936.0     342214.0         2494150.0\n",
       "           03/01/2016      2156668.0     343143.0         2499811.0\n",
       "           03/02/2015      2154140.0     342541.0         2496681.0\n",
       "           03/02/2016      2159107.0     343636.0         2502743.0\n",
       "           03/03/2015      2154068.0     342652.0         2496720.0\n",
       "           03/03/2016      2158936.0     343655.0         2502591.0\n",
       "           03/04/2015      2150710.0     342596.0         2493306.0\n",
       "           03/04/2016      2155632.0     343580.0         2499212.0\n",
       "           03/05/2015      2150726.0     342514.0         2493240.0\n",
       "           03/05/2016      2156535.0     343656.0         2500191.0\n",
       "           03/06/2016        20011.0      21791.0           41802.0\n",
       "           03/07/2015      2146870.0     342550.0         2489420.0\n",
       "           03/07/2016      2149822.0     343268.0         2493090.0\n",
       "           03/08/2015      2145564.0     342297.0         2487861.0\n",
       "           03/08/2016      2150316.0     343194.0         2493510.0\n",
       "           03/09/2015      2147206.0     342648.0         2489854.0\n",
       "           03/09/2016      2151783.0     343643.0         2495426.0\n",
       "           03/10/2015      2146387.0     342610.0         2488997.0\n",
       "           03/10/2016      2151705.0     343552.0         2495257.0\n",
       "           03/11/2015      2145743.0     342412.0         2488155.0\n",
       "           03/11/2016      2152120.0     343393.0         2495513.0\n",
       "           03/12/2015      2145805.0     342452.0         2488257.0\n",
       "           03/12/2016      2151444.0     343677.0         2495121.0\n",
       "           03/13/2015      2144862.0     342644.0         2487506.0\n",
       "           03/13/2016      2149273.0     343645.0         2492918.0\n",
       "           03/14/2015      2137977.0     342647.0         2480624.0\n",
       "           03/14/2016      2140598.0     343245.0         2483843.0\n",
       "...                              ...          ...               ...\n",
       "ZEREGA AVE 06/11/2015       756273.0     705710.0         1461983.0\n",
       "           06/11/2016       759119.0     708101.0         1467220.0\n",
       "           06/12/2015       756613.0     705862.0         1462475.0\n",
       "           06/12/2016       758034.0     707214.0         1465248.0\n",
       "           06/13/2015       755509.0     704946.0         1460455.0\n",
       "           06/13/2016       756632.0     706040.0         1462672.0\n",
       "           06/14/2015       755343.0     704754.0         1460097.0\n",
       "           06/14/2016       758022.0     707192.0         1465214.0\n",
       "           06/15/2015       757055.0     706078.0         1463133.0\n",
       "           06/15/2016       759716.0     708502.0         1468218.0\n",
       "           06/16/2015       757361.0     706304.0         1463665.0\n",
       "           06/16/2016       760171.0     708844.0         1469015.0\n",
       "           06/17/2015       757753.0     706566.0         1464319.0\n",
       "           06/17/2016       760479.0     709016.0         1469495.0\n",
       "           06/18/2015       758014.0     706700.0         1464714.0\n",
       "           06/18/2016       760688.0     709127.0         1469815.0\n",
       "           06/19/2015       758242.0     706811.0         1465053.0\n",
       "           06/19/2016       759717.0     708156.0         1467873.0\n",
       "           06/20/2015       757393.0     706015.0         1463408.0\n",
       "           06/20/2016       758461.0     707110.0         1465571.0\n",
       "           06/21/2015       757334.0     706385.0         1463719.0\n",
       "           06/21/2016       759965.0     708742.0         1468707.0\n",
       "           06/22/2015       759091.0     708071.0         1467162.0\n",
       "           06/22/2016       761784.0     710428.0         1472212.0\n",
       "           06/23/2015       759371.0     708280.0         1467651.0\n",
       "           06/23/2016       762036.0     710701.0         1472737.0\n",
       "           06/24/2015       759738.0     708469.0         1468207.0\n",
       "           06/24/2016       762407.0     710699.0         1473106.0\n",
       "           06/25/2015       760005.0     708449.0         1468454.0\n",
       "           06/26/2015         2385.0       2152.0            4537.0\n",
       "\n",
       "[89103 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Users/gabrielruiz/anaconda/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2133\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2134\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Datetime'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-4cc9ff3739c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdtp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Day_of_week'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Datetime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%A\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/gabrielruiz/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielruiz/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielruiz/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielruiz/anaconda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3543\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3544\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gabrielruiz/anaconda/lib/python3.6/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Datetime'"
     ]
    }
   ],
   "source": [
    "dtp['Day_of_week'] = dtp['Datetime'].apply(lambda row: row.strftime(\"%A\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htp['Day_of_week'] = htp['Datetime'].apply(lambda row: row.strftime(\"%A\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htp['Hour'] = htp['Datetime'].apply(lambda row: row.strftime(\"%-I%p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eight_am_mask = (htp['Hour'] == '8AM')\n",
    "four_pm_mask = (htp['Hour'] == '4PM')\n",
    "twelve_pm_mask = (htp['Hour'] == '12PM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htp_8am = htp.loc[eight_am_mask,:].groupby(['Station','Day_of_week','Hour']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Throughput</th>\n",
       "      <th>Day_of_week</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10AM</th>\n",
       "      <td>52570</td>\n",
       "      <td>52570</td>\n",
       "      <td>52570</td>\n",
       "      <td>52570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10PM</th>\n",
       "      <td>45428</td>\n",
       "      <td>45428</td>\n",
       "      <td>45428</td>\n",
       "      <td>45428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11AM</th>\n",
       "      <td>83247</td>\n",
       "      <td>83247</td>\n",
       "      <td>83247</td>\n",
       "      <td>83247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11PM</th>\n",
       "      <td>80074</td>\n",
       "      <td>80074</td>\n",
       "      <td>80074</td>\n",
       "      <td>80074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12AM</th>\n",
       "      <td>571223</td>\n",
       "      <td>571223</td>\n",
       "      <td>571223</td>\n",
       "      <td>571223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12PM</th>\n",
       "      <td>579242</td>\n",
       "      <td>579242</td>\n",
       "      <td>579242</td>\n",
       "      <td>579242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1AM</th>\n",
       "      <td>374861</td>\n",
       "      <td>374861</td>\n",
       "      <td>374861</td>\n",
       "      <td>374861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1PM</th>\n",
       "      <td>381062</td>\n",
       "      <td>381062</td>\n",
       "      <td>381062</td>\n",
       "      <td>381062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2AM</th>\n",
       "      <td>43981</td>\n",
       "      <td>43981</td>\n",
       "      <td>43981</td>\n",
       "      <td>43981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2PM</th>\n",
       "      <td>46803</td>\n",
       "      <td>46803</td>\n",
       "      <td>46803</td>\n",
       "      <td>46803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3AM</th>\n",
       "      <td>80005</td>\n",
       "      <td>80005</td>\n",
       "      <td>80005</td>\n",
       "      <td>80005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3PM</th>\n",
       "      <td>81477</td>\n",
       "      <td>81477</td>\n",
       "      <td>81477</td>\n",
       "      <td>81477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4AM</th>\n",
       "      <td>576318</td>\n",
       "      <td>576318</td>\n",
       "      <td>576318</td>\n",
       "      <td>576318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4PM</th>\n",
       "      <td>577286</td>\n",
       "      <td>577286</td>\n",
       "      <td>577286</td>\n",
       "      <td>577286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5AM</th>\n",
       "      <td>380235</td>\n",
       "      <td>380235</td>\n",
       "      <td>380235</td>\n",
       "      <td>380235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5PM</th>\n",
       "      <td>380847</td>\n",
       "      <td>380847</td>\n",
       "      <td>380847</td>\n",
       "      <td>380847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6AM</th>\n",
       "      <td>48690</td>\n",
       "      <td>48690</td>\n",
       "      <td>48690</td>\n",
       "      <td>48690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6PM</th>\n",
       "      <td>45578</td>\n",
       "      <td>45578</td>\n",
       "      <td>45578</td>\n",
       "      <td>45578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7AM</th>\n",
       "      <td>100114</td>\n",
       "      <td>100114</td>\n",
       "      <td>100114</td>\n",
       "      <td>100114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7PM</th>\n",
       "      <td>81094</td>\n",
       "      <td>81094</td>\n",
       "      <td>81094</td>\n",
       "      <td>81094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8AM</th>\n",
       "      <td>597525</td>\n",
       "      <td>597525</td>\n",
       "      <td>597525</td>\n",
       "      <td>597525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8PM</th>\n",
       "      <td>576221</td>\n",
       "      <td>576221</td>\n",
       "      <td>576221</td>\n",
       "      <td>576221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9AM</th>\n",
       "      <td>389749</td>\n",
       "      <td>389749</td>\n",
       "      <td>389749</td>\n",
       "      <td>389749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9PM</th>\n",
       "      <td>380813</td>\n",
       "      <td>380813</td>\n",
       "      <td>380813</td>\n",
       "      <td>380813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Station  Datetime  Throughput  Day_of_week\n",
       "Hour                                            \n",
       "10AM    52570     52570       52570        52570\n",
       "10PM    45428     45428       45428        45428\n",
       "11AM    83247     83247       83247        83247\n",
       "11PM    80074     80074       80074        80074\n",
       "12AM   571223    571223      571223       571223\n",
       "12PM   579242    579242      579242       579242\n",
       "1AM    374861    374861      374861       374861\n",
       "1PM    381062    381062      381062       381062\n",
       "2AM     43981     43981       43981        43981\n",
       "2PM     46803     46803       46803        46803\n",
       "3AM     80005     80005       80005        80005\n",
       "3PM     81477     81477       81477        81477\n",
       "4AM    576318    576318      576318       576318\n",
       "4PM    577286    577286      577286       577286\n",
       "5AM    380235    380235      380235       380235\n",
       "5PM    380847    380847      380847       380847\n",
       "6AM     48690     48690       48690        48690\n",
       "6PM     45578     45578       45578        45578\n",
       "7AM    100114    100114      100114       100114\n",
       "7PM     81094     81094       81094        81094\n",
       "8AM    597525    597525      597525       597525\n",
       "8PM    576221    576221      576221       576221\n",
       "9AM    389749    389749      389749       389749\n",
       "9PM    380813    380813      380813       380813"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htp.groupby(['Hour']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Throughput</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_of_week</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Friday</th>\n",
       "      <td>ZEREGA AVE</td>\n",
       "      <td>8AM</td>\n",
       "      <td>8.384000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Monday</th>\n",
       "      <td>ZEREGA AVE</td>\n",
       "      <td>8AM</td>\n",
       "      <td>7.694750e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saturday</th>\n",
       "      <td>ZEREGA AVE</td>\n",
       "      <td>8AM</td>\n",
       "      <td>2.666094e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunday</th>\n",
       "      <td>ZEREGA AVE</td>\n",
       "      <td>8AM</td>\n",
       "      <td>1.149430e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thursday</th>\n",
       "      <td>ZEREGA AVE</td>\n",
       "      <td>8AM</td>\n",
       "      <td>6.201800e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuesday</th>\n",
       "      <td>ZEREGA AVE</td>\n",
       "      <td>8AM</td>\n",
       "      <td>8.487320e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wednesday</th>\n",
       "      <td>ZEREGA AVE</td>\n",
       "      <td>8AM</td>\n",
       "      <td>3.182406e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Station Hour    Throughput\n",
       "Day_of_week                               \n",
       "Friday       ZEREGA AVE  8AM  8.384000e+07\n",
       "Monday       ZEREGA AVE  8AM  7.694750e+05\n",
       "Saturday     ZEREGA AVE  8AM  2.666094e+06\n",
       "Sunday       ZEREGA AVE  8AM  1.149430e+05\n",
       "Thursday     ZEREGA AVE  8AM  6.201800e+05\n",
       "Tuesday      ZEREGA AVE  8AM  8.487320e+05\n",
       "Wednesday    ZEREGA AVE  8AM  3.182406e+09"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htp_8am.groupby(['Day_of_week']).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration \n",
    "::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The column names contain unneeded whitespace.\n",
    "df1.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The dataframe also lacks a timeseries.\n",
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Strip whitespace from column names\n",
    "df1.columns = [s.strip() for s in df1.columns.values]\n",
    "\n",
    "# Create datetime column with datetime datatype\n",
    "df1['Datetime'] = pd.to_datetime(df1.DATE + ' ' + df1.TIME,\n",
    "                                 format = '%m/%d/%Y %H:%M:%S')\n",
    "\n",
    "df1.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chain methods together to further clean data:\n",
    "    # drop old date and time columns\n",
    "    # rename columns\n",
    "    \n",
    "dict_col_rename = {'C/A' : 'C_A', 'UNIT' : 'Unit', 'STATION' : 'Station', 'LINENAME' : 'Linename',\n",
    "                  'DIVISION' : 'Division', 'DESC' : 'Desc', 'ENTRIES' : 'Entries', 'EXITS' : 'Exits',\n",
    "                  'DATE' : 'Date'}    \n",
    "\n",
    "df2 = (df1\n",
    "       #.drop('DATE', axis = 1)\n",
    "       .drop('TIME', axis = 1)\n",
    "       .rename(columns = dict_col_rename)\n",
    "      )\n",
    "\n",
    "df2.iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Erroneous Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check uniqueness of rows/indexes by getting counts.\n",
    "(df2\n",
    " .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Datetime'])\n",
    " .count() #.Entries.count()\n",
    " .reset_index()\n",
    " .sort_values('Entries', ascending = False)\n",
    " .iloc[:5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On 3/25, we don't seem to have two entries for same time, but let's take a look anyway.\n",
    "\n",
    "mask = ((df2[\"C_A\"] == \"A002\") & \n",
    "(df2[\"Unit\"] == \"R051\") & \n",
    "(df2[\"SCP\"] == \"02-00-00\") & \n",
    "(df2[\"Station\"] == \"59 ST\") &\n",
    "(df2[\"Datetime\"].dt.date == datetime.datetime(2017, 3, 25).date()))\n",
    "df2[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.Desc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Questions for the future, if there is time:\n",
    "    # Are there other values of DESC?\n",
    "    # Are there other fields to check for odd values?\n",
    "\n",
    "# Drop duplicates.\n",
    "df_no_dupe = df2.drop_duplicates(subset=['C_A', 'Unit', 'SCP', 'Station', 'Datetime'])\n",
    "\n",
    "# Check uniqueness again after data cleaning to confirm cleanness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_no_dupe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Entries and Exits per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_daily_entries = (df_no_dupe\n",
    "            .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Date'])\n",
    "            .Entries\n",
    "            .first()\n",
    "            .reset_index()\n",
    "           )\n",
    "\n",
    "df_daily_exits = (df_no_dupe\n",
    "            .groupby(['C_A', 'Unit', 'SCP', 'Station', 'Date'])\n",
    "            .Exits\n",
    "            .first()\n",
    "            .reset_index()\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the differences by day\n",
    "df_daily_entries[[\"Prev_date\", \"Prev_entries\"]] = (df_daily_entries\n",
    "                                                       .groupby([\"C_A\", \"Unit\", \"SCP\", \"Station\"])[\"Date\", \"Entries\"]\n",
    "                                                       .transform(lambda grp: grp.shift(1)))\n",
    "\n",
    "df_daily_exits[[\"Prev_date\", \"Prev_exits\"]]   = (df_daily_exits\n",
    "                                                       .groupby([\"C_A\", \"Unit\", \"SCP\", \"Station\"])[\"Date\", \"Exits\"]\n",
    "                                                       .transform(lambda grp: grp.shift(1)))\n",
    "\n",
    "# Drop all the null values generated above\n",
    "df_daily_entries.dropna(subset=[\"Prev_date\"], axis=0, inplace=True)\n",
    "df_daily_exits.dropna(subset=[\"Prev_date\"], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_daily_entries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for any counters that have been reversed\n",
    "df_daily_entries[df_daily_entries[\"Entries\"] < df_daily_entries[\"Prev_entries\"]].head()\n",
    "\n",
    "# WTC: Is this something that can be solved by sorting before applying the transform above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### HAVE NOT EDITED YET\n",
    "\n",
    "# Pick a value from one of the counters reversed above & check for it \n",
    "# What's the deal with counter being in reverse\n",
    "# mask = ((turnstiles_df[\"C/A\"] == \"A011\") & \n",
    "# (turnstiles_df[\"UNIT\"] == \"R080\") & \n",
    "# (turnstiles_df[\"SCP\"] == \"01-00-00\") & \n",
    "# (turnstiles_df[\"STATION\"] == \"57 ST-7 AV\") &\n",
    "# (turnstiles_df[\"DATE_TIME\"].dt.date == datetime.datetime(2016, 8, 27).date()))\n",
    "# turnstiles_df[mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's see how many stations have this problem\n",
    "\n",
    "(df_daily_entries[df_daily_entries[\"Entries\"] < df_daily_entries[\"Prev_entries\"]]\n",
    "    .groupby([\"C_A\", \"Unit\", \"SCP\", \"Station\"])\n",
    "    .size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def get_daily_counts(row, max_counter, cols):\n",
    "#     counter = row[cols[0]] - row[cols[1]]\n",
    "#     if counter < 0:\n",
    "#         # May be counter is reversed?\n",
    "#         counter = -counter\n",
    "#     if counter > max_counter:\n",
    "#         print(row[cols[0]], row[cols[1]])\n",
    "#         counter = min(row[cols[0]], row[cols[1]])\n",
    "#     if counter > max_counter:\n",
    "#         # Check it again to make sure we are not giving a counter that's too big\n",
    "#         return 0\n",
    "#     return counter\n",
    "\n",
    "# If counter is > 1Million, then the counter might have been reset.  \n",
    "# Just set it to zero as different counters have different cycle limits\n",
    "df_daily_entries[\"Daily_Entries\"] = df_daily_entries.apply(get_daily_counts, axis=1, args=(1000000, ['Entries', 'Prev_entries']))\n",
    "df_daily_exits[\"Daily_Exits\"] = df_daily_exits.apply(get_daily_counts, axis=1, args=(1000000, ['Exits', 'Prev_exits']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_daily_entries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_daily_exits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_daily = pd.merge(df_daily_entries, df_daily_exits, on=['C_A','Unit','SCP', 'Station', 'Date', 'Prev_date'])\n",
    "df_daily['Total_throughput'] = df_daily['Daily_Entries'] + df_daily['Daily_Exits']\n",
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df_daily\n",
    " .groupby(['Station', 'Date'])\n",
    " .sum()\n",
    "#  .sort_values(by=['Total_throughput'], ascending=False)\n",
    " .loc[:,['Daily_Entries', 'Daily_Exits', 'Total_throughput']]\n",
    "#  .frame()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Entries and Exits per Hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use concat (as a join) to fix (\"de-cumulate\") the columns Entries and Exits\n",
    "\n",
    "df_shift = (df_no_dupe\n",
    "            .copy()\n",
    "            .drop('Linename', axis = 1)\n",
    "            .drop('Division', axis = 1)\n",
    "           )\n",
    "\n",
    "df_shift[['Datetime_Prev', 'Entries_Prev', 'Exits_Prev']] = (df_shift\n",
    "            .groupby(['C_A', 'Unit', 'SCP', 'Station'])['Datetime', 'Entries', 'Exits']\n",
    "            .transform(lambda grp: grp.shift(1)))\n",
    "\n",
    "df_shift.head()\n",
    "\n",
    "\n",
    "# Legacy\n",
    "\n",
    "# df_shift.columns\n",
    "# df_shift['Datetime_Prev', 'Entries_Prev', 'Exits_Prev'] = (\n",
    "#     df_no_dupe#[['C_A', 'Unit', 'SCP', 'Station', 'Datetime', 'Entries', 'Exits']]\n",
    "#             .groupby(['C_A', 'Unit', 'SCP', 'Station'])['Datetime', 'Entries', 'Exits']\n",
    "#             #.groupby([\"C/A\", \"UNIT\", \"SCP\", \"STATION\"])[\"DATE\", \"ENTRIES\"]\n",
    "#             .transform(lambda grp: grp.shift(1))\n",
    "#             #.shift(periods = 1)\n",
    "#             #.rename(columns = {'Entries' : 'Entries_Shift', 'Exits' : 'Exits_Shift', \n",
    "#             #                   'Datetime' : 'Prev_datetime'})\n",
    "#            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_shift['Entries'] = df_shift['Entries'] - df_shift['Entries_Prev']\n",
    "df_shift['Exits'] = df_shift['Exits'] - df_shift['Exits_Prev']\n",
    "df_shift = df_shift.dropna(how = 'any')\n",
    "\n",
    "df_shift.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Challenge 3 - Total Daily Entries\n",
    "#df3or4['Datetime'].dt.date == datetime.datetime(YYYY, MM, DD).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_daily_counts(row, max_counter):\n",
    "#     counter = abs(row[\"ENTRIES\"] - row[\"PREV_ENTRIES\"])\n",
    "    \n",
    "#     if counter > max_counter:\n",
    "#         print(row[\"ENTRIES\"], row[\"PREV_ENTRIES\"])\n",
    "#         return 0\n",
    "#     return counter\n",
    "\n",
    "# # If counter is > 1Million, then the counter might have been reset.  \n",
    "# # Just set it to zero as different counters have different cycle limits\n",
    "# _ = turnstiles_daily.apply(get_daily_counts, axis=1, max_counter=1000000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
